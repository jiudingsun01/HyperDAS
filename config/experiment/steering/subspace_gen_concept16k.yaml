defaults:
  - /model/gemma2b_lsreft
  - /dataset/concept16k_2b_l20
  - /training/base
  - /loss/base
  - /wandb_config/base
  - /axbench/lsreft_concept16k
  - _self_

training:
  lr: 3e-5
  n_epochs: 10
  test_per_steps: 500
  log_per_steps: 10
  save_model: true
  debug_model: false
  train_batch_size: 32
  test_batch_size: 16
  checkpoint_per_steps: 2000
  scheduler_type: linear
  warmup_ratio: 0.2

model:
  max_length: 256
  das_dimension: 1
  objective: reconstruction
  concept_detection: false
  intervention_layer: [20]

dataset:
  eval_path: null

loss:
  return_penalty: false

wandb_config:
  project: HyperReFT_Steering
  run_name: gemma2b_hyperlsreft_concept16k_steer

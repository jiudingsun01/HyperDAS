[2025-02-11 22:45:04,180][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-11 22:45:04,181][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-11 22:45:04,181][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-11 22:45:04,181][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-11 22:45:04,217][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-11 22:45:04,224][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 2
  - 4
  - 6
  - 8
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: pyvene/axbench-concept16k
  test_path: ''
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 8
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-11 22:45:06,365][__main__][DEBUG] - Splitting axbench train set into train and test sets
[2025-02-11 22:45:49,634][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-11 22:45:49,636][src.hyperdas.llama3.model][INFO] - 
Completed generation for 128 examples
[2025-02-11 22:45:49,713][__main__][ERROR] - An error occurred in hydra_main: Key 'name_or_path' is not in struct
    full_key: experiment.name_or_path
    object_type=dict
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 242, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 187, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1335, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1173, in eval_accuracy
    self.setup_evaluators(
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1031, in setup_evaluators
    model_name=self.config.name_or_path,
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 359, in __getattr__
    self._format_and_raise(key=key, value=None, cause=e)
  File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 231, in _format_and_raise
    format_and_raise(
  File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 819, in format_and_raise
    _raise(ex, cause)
  File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 797, in _raise
    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 351, in __getattr__
    return self._get_impl(
           ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 442, in _get_impl
    node = self._get_child(
           ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/omegaconf/basecontainer.py", line 73, in _get_child
    child = self._get_node(
            ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 475, in _get_node
    self._validate_get(key)
  File "/usr/local/lib/python3.12/dist-packages/omegaconf/dictconfig.py", line 164, in _validate_get
    self._format_and_raise(
  File "/usr/local/lib/python3.12/dist-packages/omegaconf/base.py", line 231, in _format_and_raise
    format_and_raise(
  File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 899, in format_and_raise
    _raise(ex, cause)
  File "/usr/local/lib/python3.12/dist-packages/omegaconf/_utils.py", line 797, in _raise
    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
omegaconf.errors.ConfigAttributeError: Key 'name_or_path' is not in struct
    full_key: experiment.name_or_path
    object_type=dict
[2025-02-11 22:46:51,942][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-11 22:46:51,942][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-11 22:46:51,943][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-11 22:46:51,943][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-11 22:46:51,978][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-11 22:46:51,985][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 2
  - 4
  - 6
  - 8
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: pyvene/axbench-concept16k
  test_path: ''
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 8
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-11 22:46:53,876][__main__][DEBUG] - Splitting axbench train set into train and test sets
[2025-02-11 22:47:37,337][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-11 22:47:37,338][src.hyperdas.llama3.model][INFO] - 
Completed generation for 128 examples
[2025-02-11 22:47:37,390][axbench.evaluators.lm_judge][WARNING] - Starting task for concept_id: None, model: gpt-4o-mini-2024-07-18, evaluator: LMJudgeEvaluator
[2025-02-11 22:47:37,411][__main__][ERROR] - An error occurred in hydra_main: 'gpt-4o-mini-2024-07-18_steered_generation'
Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'gpt-4o-mini-2024-07-18_steered_generation'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 242, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 187, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1335, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1177, in eval_accuracy
    metrics = self.evaluate_axbench(eval_df)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1055, in evaluate_axbench
    lm_judge_metrics = self.lm_judge_evaluator.compute_metrics(eval_data)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/axbench/axbench/evaluators/lm_judge.py", line 111, in compute_metrics
    self._get_all_ratings_from_data(data_copy, self.model_name)
  File "/workspace/HyperDAS/axbench/axbench/evaluators/lm_judge.py", line 70, in _get_all_ratings_from_data
    generation = row[f"{column_name}_steered_generation"]
                 ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pandas/core/series.py", line 1121, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pandas/core/series.py", line 1237, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'gpt-4o-mini-2024-07-18_steered_generation'
[2025-02-11 22:53:27,908][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-11 22:53:27,908][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-11 22:53:27,908][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-11 22:53:27,908][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-11 22:53:27,945][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-11 22:53:27,955][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 2
  - 4
  - 6
  - 8
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: pyvene/axbench-concept16k
  test_path: ''
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 8
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-11 22:53:29,171][__main__][DEBUG] - Splitting axbench train set into train and test sets
[2025-02-11 22:54:12,045][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-11 22:54:12,046][src.hyperdas.llama3.model][INFO] - 
Completed generation for 128 examples
[2025-02-11 22:54:12,109][axbench.evaluators.lm_judge][WARNING] - Starting task for concept_id: None, model: TinyLlama/TinyLlama_v1.1, evaluator: LMJudgeEvaluator
[2025-02-11 22:54:14,068][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,242][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,315][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,352][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,375][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,455][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,467][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,487][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,531][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,568][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,580][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,660][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,674][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,721][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,750][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,752][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,807][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,920][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,923][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,939][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,942][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,965][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:14,986][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:15,066][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:15,081][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:15,355][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:15,542][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:15,604][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:15,606][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:15,703][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:15,828][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:15,916][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:17,068][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:17,105][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:17,109][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:17,207][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:17,366][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:17,464][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:17,502][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:17,685][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:17,747][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:17,855][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:17,861][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:17,888][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:18,058][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:18,116][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:18,206][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:18,263][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:19,584][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:19,677][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:19,694][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:19,705][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:19,709][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:19,792][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:19,821][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:19,897][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:19,924][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:19,955][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:20,016][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:20,026][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:20,110][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:20,137][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:20,397][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:24,876][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,025][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,151][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,342][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,360][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,438][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,454][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,551][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,553][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,579][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,636][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,643][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,706][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,743][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:26,879][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:27,379][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:27,621][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:28,803][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,079][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,166][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,248][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,355][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,377][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,472][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,561][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,563][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,564][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,590][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,669][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,683][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,734][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,751][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,851][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,855][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,858][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,863][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:29,914][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:30,070][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:30,196][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:30,219][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:30,232][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:30,284][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:30,295][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:30,543][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:30,712][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:30,873][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:31,151][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:31,170][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:34,045][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,268][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,420][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,432][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,549][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,585][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,594][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,619][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,650][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,816][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,864][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,865][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,872][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:35,972][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,007][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,011][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,061][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,128][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,212][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,251][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,319][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,322][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,408][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,451][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,455][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,494][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,495][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,513][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,782][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,862][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:36,981][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:37,343][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:39,357][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:40,588][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:40,728][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:40,745][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:40,801][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:40,831][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:40,852][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:40,867][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:40,904][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:40,906][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:40,973][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:40,985][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:41,014][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:41,049][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:41,165][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:41,181][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:41,246][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:41,333][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:41,401][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:41,480][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:41,638][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:41,836][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:41,919][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:42,045][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:42,139][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:42,215][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:42,231][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:42,293][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:42,488][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:43,045][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:43,271][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:45,288][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:48,132][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:49,365][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:49,534][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:49,596][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:49,620][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:49,672][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:49,733][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:49,745][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:49,758][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:49,832][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:49,855][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:49,864][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:49,982][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,001][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,010][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,011][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,013][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,051][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,055][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,085][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,091][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,104][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,122][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,280][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,386][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,394][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,419][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,565][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:50,904][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:51,018][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:51,264][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:51,458][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:52,505][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:53,952][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:53,986][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:53,989][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,046][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,137][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,176][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,191][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,255][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,455][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,475][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,526][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,638][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,662][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,687][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,773][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,912][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:54,969][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,076][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,081][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,113][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,168][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,385][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,507][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,516][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,518][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,608][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,654][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,720][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,728][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:55,785][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:54:56,428][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:02,226][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:04,134][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:04,321][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:04,494][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:04,613][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:04,616][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:04,692][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:04,738][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:04,768][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:04,957][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:04,975][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:05,137][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:05,200][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:05,479][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:06,015][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:07,680][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:13,973][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:15,421][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:15,612][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:15,868][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:15,893][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:16,304][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:16,355][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:16,499][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:16,557][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:16,772][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:16,780][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:16,788][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:16,848][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:17,059][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:17,118][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:17,173][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:21,171][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:22,615][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:22,658][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:22,835][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:22,928][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:23,014][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:23,191][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:23,225][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:23,393][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:23,482][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:23,550][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:23,669][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:23,992][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:24,017][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:24,048][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:24,190][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:25,824][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-11 22:55:25,873][__main__][ERROR] - An error occurred in hydra_main: 'NoneType' object has no attribute 'chat_completions'
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 242, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 187, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1335, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1177, in eval_accuracy
    metrics = self.evaluate_axbench(eval_df)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1056, in evaluate_axbench
    winrate_metrics = self.winrate_evaluator.compute_metrics(eval_data)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/axbench/axbench/evaluators/winrate.py", line 108, in compute_metrics
    self._get_all_ratings_from_data(data_copy, self.winrate_baseline)
  File "/workspace/HyperDAS/axbench/axbench/evaluators/winrate.py", line 84, in _get_all_ratings_from_data
    model_relevance_concept_ratings = self._get_ratings_from_prompts(model_relevance_concept_prompts, f"{column_name}_concept")
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/axbench/axbench/evaluators/winrate.py", line 61, in _get_ratings_from_prompts
    completions = asyncio.run(process_batch())
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 194, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/runners.py", line 118, in run
    return self._loop.run_until_complete(task)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/asyncio/base_events.py", line 686, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/axbench/axbench/evaluators/winrate.py", line 56, in process_batch
    return await self.lm_model.chat_completions(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'chat_completions'
[2025-02-13 04:17:11,321][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 04:17:11,322][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 04:17:11,322][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 04:17:11,322][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 04:17:11,488][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 04:17:11,497][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 2
  - 4
  - 6
  - 8
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: ''
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 500
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: -1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 04:17:15,074][__main__][DEBUG] - Splitting axbench train set into train and test sets
[2025-02-13 04:20:29,179][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 04:20:29,179][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 04:20:29,179][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 04:20:29,180][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 04:20:29,298][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 04:20:29,307][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 2
  - 4
  - 6
  - 8
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 500
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: -1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 04:49:41,823][__main__][ERROR] - An error occurred in hydra_main: 
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 242, in main
  File "/workspace/HyperDAS/train.py", line 187, in run_experiment
    if torch.backends.mps.is_available()
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1338, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1170, in eval_accuracy
    eval_df = pd.DataFrame(eval_data)
              ^^
  File "/usr/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2025-02-13 05:32:32,800][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 05:32:32,800][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 05:32:32,801][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 05:32:32,801][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 05:32:32,931][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 05:32:32,940][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 500
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: -1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 05:33:12,649][__main__][ERROR] - An error occurred in hydra_main: The following `model_kwargs` are not used by the model: ['_input_ids', '_attention_mask'] (note: typos in the generate arguments will also show up in this list)
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1340, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1165, in eval_accuracy
    raise e
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1092, in eval_accuracy
    outputs_with_intervention = self.interpretor.generate(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/modules.py", line 621, in generate
    outputs = self.target_model.generate(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py", line 1805, in generate
    self._validate_model_kwargs(model_kwargs.copy())
  File "/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py", line 1205, in _validate_model_kwargs
    raise ValueError(
ValueError: The following `model_kwargs` are not used by the model: ['_input_ids', '_attention_mask'] (note: typos in the generate arguments will also show up in this list)
[2025-02-13 05:33:56,523][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 05:33:56,523][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 05:33:56,523][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 05:33:56,524][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 05:33:56,655][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 05:33:56,665][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 500
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: -1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 05:34:42,826][__main__][ERROR] - An error occurred in hydra_main: list index out of range
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1340, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1165, in eval_accuracy
    raise e
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1144, in eval_accuracy
    "PromptSteering_steered_generation": baseline_texts[i],
                                         ~~~~~~~~~~~~~~^^^
IndexError: list index out of range
[2025-02-13 05:35:30,872][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 05:35:30,872][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 05:35:30,872][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 05:35:30,873][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 05:35:31,003][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 05:35:31,012][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 500
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: -1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 05:36:23,024][__main__][ERROR] - An error occurred in hydra_main: 
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1340, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1165, in eval_accuracy
    raise e
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1092, in eval_accuracy
    outputs_with_intervention = self.interpretor.generate(
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/modules.py", line 622, in generate
    outputs = self.target_model.generate(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py", line 2048, in generate
    result = self._sample(
             ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py", line 3008, in _sample
    outputs = self(**model_inputs, return_dict=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/gemma/modeling_gemma.py", line 1069, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/gemma/modeling_gemma.py", line 911, in forward
    return BaseModelOutputWithPast(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "<string>", line 7, in __init__
  File "/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py", line 365, in __post_init__
    class_fields = fields(self)
                   ^^^^^^^^^^^^
  File "/usr/lib/python3.12/dataclasses.py", line 1293, in fields
    return tuple(f for f in fields.values() if f._field_type is _FIELD)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/dataclasses.py", line 1293, in <genexpr>
    return tuple(f for f in fields.values() if f._field_type is _FIELD)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2025-02-13 05:36:55,934][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 05:36:55,934][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 05:36:55,935][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 05:36:55,935][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 05:36:56,093][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 05:36:56,102][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 05:37:43,652][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-13 05:41:15,438][__main__][ERROR] - An error occurred in hydra_main: 
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1340, in run_train
    epoch_train_loss = 0
                         
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1172, in eval_accuracy
    )
  File "/usr/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2025-02-13 05:41:26,283][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 05:41:26,283][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 05:41:26,283][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 05:41:26,283][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 05:41:26,419][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 05:41:26,429][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 05:42:13,385][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-13 05:43:16,919][__main__][ERROR] - An error occurred in hydra_main: 
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1350, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1182, in eval_accuracy
    eval_df = pd.DataFrame(eval_data)
              ^^
  File "/usr/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2025-02-13 05:44:06,261][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 05:44:06,261][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 05:44:06,262][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 05:44:06,262][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 05:44:06,349][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 05:44:06,357][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 05:44:53,564][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-13 05:44:53,565][__main__][ERROR] - An error occurred in hydra_main: string indices must be integers, not 'str'
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1353, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1184, in eval_accuracy
    print(bruh["google/gemma-2b_steered_generation"])
          ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: string indices must be integers, not 'str'
[2025-02-13 05:45:40,191][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 05:45:40,191][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 05:45:40,191][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 05:45:40,191][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 05:45:40,329][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 05:45:40,338][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 05:46:27,306][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-13 05:46:47,936][__main__][ERROR] - An error occurred in hydra_main: 
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1354, in run_train
    for loader in test_loader:
                               
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1188, in eval_accuracy
  File "/usr/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2025-02-13 05:47:00,050][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 05:47:00,050][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 05:47:00,050][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 05:47:00,051][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 05:47:00,185][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 05:47:00,194][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 05:47:47,197][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-13 05:47:49,305][__main__][ERROR] - An error occurred in hydra_main: 
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1355, in run_train
    if cur_steps % eval_per_steps == 0:
                                   ^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1189, in eval_accuracy
    print("=" * 100)
    ^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2025-02-13 05:48:05,631][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 05:48:05,631][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 05:48:05,631][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 05:48:05,631][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 05:48:05,763][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 05:48:05,772][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 05:48:52,665][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-13 05:49:34,032][__main__][ERROR] - An error occurred in hydra_main: 
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1358, in run_train
    for loader in test_loader:
                               
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1192, in eval_accuracy
  File "/usr/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2025-02-13 05:49:52,693][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 05:49:52,693][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 05:49:52,693][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 05:49:52,693][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 05:49:52,791][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 05:49:52,799][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 05:50:40,700][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-13 05:54:10,471][__main__][ERROR] - An error occurred in hydra_main: 
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1359, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1193, in eval_accuracy
    logger.info(f"\nCompleted generation for {len(eval_data)} examples")
    ^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2025-02-13 05:54:21,470][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 05:54:21,470][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 05:54:21,470][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 05:54:21,470][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 05:54:21,607][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 05:54:21,617][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 05:55:09,444][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-13 05:55:09,446][src.hyperdas.llama3.model][INFO] - 
Completed generation for 128 examples
[2025-02-13 05:55:09,493][axbench.evaluators.lm_judge][WARNING] - Starting task for concept_id: None, model: TinyLlama/TinyLlama_v1.1, evaluator: LMJudgeEvaluator
[2025-02-13 05:55:10,986][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,156][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,197][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,310][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,421][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,484][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,566][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,583][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,702][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,717][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,765][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,828][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,943][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:11,967][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,002][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,021][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,036][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,129][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,140][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,170][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,196][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,207][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,270][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,295][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,303][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,370][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,494][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,618][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,737][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,779][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,953][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:12,992][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:14,414][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:14,534][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:14,547][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:14,577][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:14,683][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:14,769][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:14,826][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:14,838][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:14,853][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:14,904][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:15,039][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:15,040][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:15,120][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:15,210][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:16,272][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:16,491][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:16,511][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:16,514][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:16,612][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:16,641][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:16,767][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:16,918][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:16,928][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:17,002][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:17,009][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:17,042][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:17,140][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:17,183][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:18,521][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:18,525][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:18,552][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:18,564][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:18,652][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:18,688][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:18,706][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:18,792][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:18,904][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:18,995][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:19,107][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:19,158][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:19,169][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:22,959][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:23,919][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,133][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,185][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,219][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,221][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,256][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,318][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,321][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,327][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,330][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,336][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,369][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,438][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,445][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,503][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,515][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,524][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,553][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,660][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,676][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,677][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,702][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,711][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,722][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,738][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,833][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,875][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:24,893][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:25,032][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:25,059][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:25,100][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:25,970][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,084][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,131][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,193][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,233][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,248][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,263][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,290][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,315][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,342][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,359][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,415][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,438][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,516][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,624][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,631][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,679][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,722][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,739][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,844][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,912][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:27,939][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:28,029][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:28,259][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:28,273][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:28,308][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:28,848][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:28,906][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:28,995][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:29,329][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:29,874][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:30,017][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:32,799][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:33,920][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:33,923][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:33,984][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:33,994][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,008][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,052][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,067][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,188][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,217][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,229][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,235][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,237][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,300][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,332][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,339][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,359][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,360][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,413][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,442][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,460][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,471][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,648][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,667][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,712][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,730][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,749][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,854][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:34,931][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:35,025][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:35,152][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:35,217][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:35,620][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:36,770][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:36,851][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:36,860][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:36,861][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:36,892][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:36,914][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:36,938][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:36,955][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:36,993][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:36,993][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,067][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,148][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,187][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,266][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,277][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,317][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,337][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,398][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,404][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,443][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,493][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,505][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,611][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,633][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,685][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,753][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,755][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,769][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,770][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:37,949][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:38,035][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:38,359][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,264][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,268][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,420][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,443][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,565][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,696][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,727][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,736][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,853][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,861][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,894][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,923][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,927][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,939][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,960][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:39,973][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,006][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,011][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,059][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,177][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,226][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,255][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,320][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,348][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,351][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,461][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,603][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,733][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,816][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,827][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:40,938][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:42,142][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:43,664][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:43,790][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:43,895][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:43,899][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:43,938][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:43,979][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:44,014][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:44,017][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:44,055][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:44,136][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:44,286][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:44,561][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:44,954][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:46,155][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:47,671][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:47,683][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:47,837][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:47,856][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:47,920][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:48,155][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:48,253][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:48,295][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:48,473][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:48,586][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:48,716][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:49,035][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:49,175][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:49,633][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:51,217][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:51,377][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:51,472][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:51,486][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:51,746][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:51,890][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:51,909][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:51,912][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:52,302][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:52,312][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:52,551][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:52,555][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:52,728][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:52,797][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:52,810][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no actual sentence fragment provided for evaluation. Please provide a sentence fragment so I can assess its fluency.
[2025-02-13 05:55:52,810][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:55:52,810][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no content provided between the brackets for evaluation. Without a sentence fragment to assess, I cannot comment on its fluency or provide a rating. Please provide a sentence fragment for review.
[2025-02-13 05:55:52,810][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:55:52,810][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:55:52,811][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no content provided between the brackets for evaluation. Without a sentence fragment to assess, I cannot comment on its fluency or provide a rating. Please provide a sentence fragment for review.
[2025-02-13 05:55:52,811][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no content provided between the brackets for evaluation. Without a sentence fragment to assess, I cannot comment on its fluency or provide a rating. Please provide a sentence fragment for review.
[2025-02-13 05:55:52,811][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no content provided between the brackets for evaluation. Without a sentence fragment to assess, I cannot comment on its fluency or provide a rating. Please provide a sentence fragment for review.
[2025-02-13 05:55:52,811][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:55:53,859][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:53,952][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,007][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,028][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,041][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,085][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,116][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,205][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,213][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,281][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,300][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,312][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,318][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,341][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,351][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,379][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,417][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,442][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,449][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,606][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:54,634][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:55,510][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:56,866][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:56,895][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:56,910][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:56,919][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:56,920][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:56,986][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,124][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,126][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,128][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,169][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,187][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,207][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,248][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,253][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,283][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,301][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,383][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,431][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,460][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,479][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,548][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,549][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,626][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,645][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,738][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,739][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:57,901][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:58,050][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:55:59,589][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:01,652][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:02,880][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:02,895][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:02,926][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,018][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,088][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,113][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,120][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,121][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,127][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,164][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,166][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,177][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,205][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,211][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,212][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,236][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,238][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,241][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,276][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,321][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,356][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,378][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,396][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,397][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,411][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,417][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,508][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,515][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,546][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,654][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,728][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:03,859][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,116][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,133][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,231][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,249][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,258][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,268][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,280][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,288][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,291][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,341][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,364][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,403][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,435][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,447][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,462][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,488][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,513][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,577][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,582][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,598][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,641][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,863][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,872][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,881][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:05,882][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:06,120][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:06,328][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:06,475][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:06,498][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:08,027][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,196][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,225][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,245][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,272][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,280][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,310][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,348][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,399][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,460][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,470][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,486][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,499][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,589][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,627][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,666][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,673][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,680][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,838][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,840][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,842][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,869][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,881][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:09,941][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:10,034][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:10,061][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:10,123][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:10,515][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:11,456][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:12,619][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:12,899][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,040][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,093][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,126][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,132][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,148][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,157][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,189][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,233][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,259][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,265][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,306][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,326][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,415][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,448][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,544][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,628][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,882][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:13,934][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:14,252][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:14,258][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:14,300][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:14,627][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:14,768][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:14,930][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:15,191][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:15,284][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:18,324][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:20,980][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,363][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,448][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,530][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,618][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,627][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,650][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,677][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,741][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,802][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,858][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,915][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,917][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:22,982][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,031][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,121][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,208][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,242][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,248][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,361][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,396][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,440][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,613][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,637][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,660][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,901][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,910][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,919][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:23,977][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:24,067][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:24,560][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:24,863][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:27,404][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:28,357][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:28,754][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:28,902][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:28,916][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:28,926][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:28,982][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:28,993][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,041][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,047][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,087][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,112][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,128][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,140][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,182][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,199][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,235][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,321][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,328][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,402][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,426][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,446][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,737][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,772][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,915][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:29,992][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:30,024][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:30,049][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:30,144][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:30,442][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:30,522][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:30,835][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:32,379][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:33,655][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:33,767][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,147][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,261][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,361][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,400][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,421][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,429][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,455][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,464][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,476][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,490][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,519][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,604][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,607][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,644][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,735][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,748][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,870][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,871][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:34,873][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:35,258][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:36,719][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:36,914][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:36,917][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:36,955][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,134][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,262][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,269][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,276][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,281][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,331][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,342][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,367][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,479][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,485][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,580][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,665][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,667][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,707][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,755][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,757][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,769][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,780][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,802][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,857][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,904][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,906][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:37,962][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:38,137][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:38,409][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:40,114][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,568][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,602][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,604][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,697][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,753][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,759][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,901][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,939][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,950][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,960][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,961][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,966][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:41,994][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,041][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,052][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,085][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,098][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,251][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,296][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,320][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,328][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,403][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,424][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,465][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,468][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,516][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,585][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,631][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,635][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,741][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:42,891][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:43,007][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,347][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,523][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,558][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,568][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,667][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,690][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,721][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,724][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,812][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,882][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,910][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,938][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,964][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:44,965][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:45,093][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:45,231][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:45,238][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:45,265][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:45,273][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:45,315][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:45,321][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:45,359][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:45,691][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:45,779][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:46,502][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:46,654][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:46,677][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:47,303][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:47,356][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:49,038][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 05:56:49,050][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,051][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,051][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,051][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,051][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no content provided between the brackets for evaluation. Without a sentence fragment to assess, I cannot comment on its fluency or provide a rating. Please provide a sentence fragment for review.
[2025-02-13 05:56:49,051][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no content provided between the brackets for evaluation. Without a sentence fragment to assess, I cannot comment on its fluency or provide a rating. Please provide a sentence fragment for review.
[2025-02-13 05:56:49,051][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,051][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,051][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,052][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,052][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,052][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,062][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,062][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,062][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no content provided between the brackets for evaluation. Without a sentence fragment to assess, I cannot comment on its fluency or provide a rating. Please provide a sentence fragment for review.
[2025-02-13 05:56:49,062][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,062][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,062][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no content provided between the brackets for evaluation. Without a sentence fragment to assess, I cannot comment on its fluency or provide a rating. Please provide a sentence fragment for review.
[2025-02-13 05:56:49,063][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no content provided between the brackets for evaluation. Without a sentence fragment to assess, I cannot comment on its fluency or provide a rating. Please provide a sentence fragment for review.
[2025-02-13 05:56:49,063][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no content provided between the brackets for evaluation. Without a sentence fragment to assess, I cannot comment on its fluency or provide a rating. Please provide a sentence fragment for review.
[2025-02-13 05:56:49,063][axbench.evaluators.winrate][WARNING] - Cannot find rating value: There is no sentence fragment provided for evaluation. Please provide a specific sentence fragment for me to assess its fluency.
[2025-02-13 05:56:49,064][__main__][ERROR] - An error occurred in hydra_main: 'list' object has no attribute 'groupby'
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1359, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1271, in eval_accuracy
    for concept_id, concept_data in eval_data.groupby("concept_id"):
                                    ^^^^^^^^^^^^^^^^^
AttributeError: 'list' object has no attribute 'groupby'
[2025-02-13 06:00:04,547][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 06:00:04,547][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 06:00:04,548][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 06:00:04,548][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 06:00:04,905][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 06:00:04,913][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 06:00:51,850][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-13 06:04:18,545][src.hyperdas.llama3.model][INFO] - 
Completed generation for 128 examples
[2025-02-13 06:04:18,592][axbench.evaluators.lm_judge][WARNING] - Starting task for concept_id: None, model: TinyLlama/TinyLlama_v1.1, evaluator: LMJudgeEvaluator
[2025-02-13 06:04:19,679][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:19,787][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:19,800][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:19,829][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:19,856][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:19,862][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:19,981][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:19,998][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,038][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,047][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,085][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,090][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,125][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,127][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,158][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,207][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,224][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,228][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,235][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,245][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,281][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,290][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,291][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,442][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,459][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,473][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,542][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,566][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,583][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,664][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:20,686][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:24,067][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:25,368][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:25,460][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:25,490][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:25,599][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:25,666][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:25,751][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:25,773][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:25,815][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:25,837][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:25,904][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:25,923][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:26,070][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:26,130][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:26,365][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:27,811][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:27,865][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:27,869][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:27,875][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:27,894][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:27,944][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:28,060][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:28,097][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:28,126][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:28,172][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:28,245][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:28,254][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:28,263][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:28,272][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:29,529][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:29,580][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:29,635][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:29,652][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:29,671][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:29,693][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:29,716][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:29,889][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:29,933][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:30,879][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:30,923][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:30,968][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:31,194][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:04:31,320][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:14:11,297][__main__][ERROR] - An error occurred in hydra_main: 
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1359, in run_train
    loader,
            
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1201, in eval_accuracy
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1056, in evaluate_axbench
    lm_judge_metrics = self.lm_judge_evaluator.compute_metrics(eval_data)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/axbench/axbench/evaluators/lm_judge.py", line 112, in compute_metrics
    self._get_all_ratings_from_data(data_copy, self.model_name)
  File "/workspace/HyperDAS/axbench/axbench/evaluators/lm_judge.py", line 84, in _get_all_ratings_from_data
    self._get_ratings_from_prompts(model_relevance_concept_prompts, f"{column_name}_concept")
  File "/workspace/HyperDAS/axbench/axbench/evaluators/lm_judge.py", line 61, in _get_ratings_from_prompts
    return self._get_ratings_from_completions(completions, min_rating, max_rating), completions
           ^^^^
  File "/usr/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2025-02-13 06:14:22,153][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 06:14:22,153][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 06:14:22,154][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 06:14:22,154][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 06:14:22,245][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 06:14:22,255][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 06:15:13,269][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-13 06:15:13,271][src.hyperdas.llama3.model][INFO] - 
Completed generation for 128 examples
[2025-02-13 06:15:13,317][axbench.evaluators.lm_judge][WARNING] - Starting task for concept_id: None, model: TinyLlama/TinyLlama_v1.1, evaluator: LMJudgeEvaluator
[2025-02-13 06:15:14,328][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,342][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,344][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,392][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,395][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,438][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,452][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,459][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,480][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,483][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,507][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,512][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,551][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,560][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,670][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,691][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,724][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,748][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,760][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,765][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,817][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,891][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,896][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,916][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:14,933][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:15,020][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:15,066][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:15,271][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:15,598][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:15,618][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:15,899][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:18,021][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,029][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,149][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,217][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,355][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,356][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,364][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,465][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,620][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,642][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,687][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,796][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,805][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,813][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,832][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,856][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,872][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,969][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:19,994][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:20,053][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:20,100][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:20,108][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:20,625][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:21,327][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:21,859][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:21,941][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:21,954][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:21,975][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:21,991][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:22,047][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:22,052][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:22,078][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:22,137][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:22,170][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:22,286][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:22,339][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:22,529][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:22,544][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:22,568][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:23,231][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:25,359][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:26,237][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:26,426][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:26,430][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:26,449][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:26,571][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:26,627][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:26,638][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:26,654][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:26,705][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:26,795][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:26,915][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:26,949][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:27,006][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:27,102][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:27,154][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:27,187][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:27,243][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:15:28,003][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,451][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,501][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,514][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,531][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,579][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,623][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,655][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,674][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,727][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,740][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,839][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,868][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,882][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,898][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,919][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,940][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,954][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:17,989][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,009][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,020][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,033][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,069][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,070][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,140][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,197][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,202][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,234][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,243][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,261][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,324][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:18,890][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:19,056][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,128][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,195][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,229][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,337][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,369][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,387][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,421][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,422][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,439][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,447][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,449][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,472][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,474][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,523][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,530][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,563][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,566][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,600][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,653][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,751][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,790][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,833][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,915][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:20,950][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:21,010][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:21,079][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:21,134][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:21,363][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:21,744][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:21,882][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:22,424][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:23,159][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,187][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,254][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,259][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,289][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,349][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,362][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,381][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,391][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,397][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,401][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,433][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,481][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,533][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,570][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,616][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,630][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,636][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,638][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,690][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,727][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,759][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,782][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,813][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,944][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:24,945][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:25,015][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:25,124][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:25,166][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:25,378][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:25,616][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:25,828][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:26,199][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,261][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,328][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,369][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,406][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,418][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,425][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,433][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,453][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,456][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,485][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,486][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,515][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,575][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,611][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,661][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,704][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,814][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,971][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:27,998][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:28,016][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:28,058][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:28,066][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:28,131][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:28,189][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:28,509][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:28,544][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:28,584][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:28,603][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:28,824][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:28,893][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:28,928][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:16:29,275][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-13 06:21:28,305][__main__][ERROR] - An error occurred in hydra_main: 
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1358, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1200, in eval_accuracy
    metrics = self.evaluate_axbench(eval_df)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1056, in evaluate_axbench
    lm_judge_metrics = self.lm_judge_evaluator.compute_metrics(eval_data)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/axbench/axbench/evaluators/lm_judge.py", line 112, in compute_metrics
    self._get_all_ratings_from_data(data_copy, self.model_name)
  File "/workspace/HyperDAS/axbench/axbench/evaluators/lm_judge.py", line 86, in _get_all_ratings_from_data
    self._get_ratings_from_prompts(model_relevance_instruction_prompts, f"{column_name}_instruction")
  File "/workspace/HyperDAS/axbench/axbench/evaluators/lm_judge.py", line 61, in _get_ratings_from_prompts
    return self._get_ratings_from_completions(completions, min_rating, max_rating), completions
           ^^^^
  File "/usr/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2025-02-13 06:22:14,427][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 06:22:14,428][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 06:22:14,428][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 06:22:14,428][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 06:22:14,564][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 06:22:14,573][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: 100
  checkpoint_per_steps: null
  max_eval_steps: 0
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 06:22:58,916][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 0 steps
[2025-02-13 06:22:58,917][__main__][ERROR] - An error occurred in hydra_main: No successful evaluations completed
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1358, in run_train
    metrics[loader.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1177, in eval_accuracy
    raise ValueError("No successful evaluations completed")
ValueError: No successful evaluations completed
[2025-02-13 06:23:43,553][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 06:23:43,554][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 06:23:43,554][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 06:23:43,554][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 06:23:43,683][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 06:23:43,695][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: null
  checkpoint_per_steps: null
  max_eval_steps: -1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 06:24:23,783][__main__][ERROR] - An error occurred in hydra_main: cumsum() received an invalid combination of arguments - got (NoneType, dim=int), but expected one of:
 * (Tensor input, int dim, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, *, torch.dtype dtype = None, Tensor out = None)
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1411, in run_train
    prediction = self.forward(
                 ^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 946, in forward
    _pred: InterpretorModelOutput = self.interpretor(
                                    ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/modules.py", line 753, in forward
    torch.cumsum(target_attention_mask, dim=1) * target_attention_mask - 1
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: cumsum() received an invalid combination of arguments - got (NoneType, dim=int), but expected one of:
 * (Tensor input, int dim, *, torch.dtype dtype = None, Tensor out = None)
 * (Tensor input, name dim, *, torch.dtype dtype = None, Tensor out = None)

[2025-02-13 06:27:04,380][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 06:27:04,380][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 06:27:04,381][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 06:27:04,381][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 06:27:04,513][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 06:27:04,522][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: null
  checkpoint_per_steps: null
  max_eval_steps: -1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 06:27:44,129][__main__][ERROR] - An error occurred in hydra_main: 'target_position_ids'
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1424, in run_train
    target_position_ids=batch["target_position_ids"],
                        ~~~~~^^^^^^^^^^^^^^^^^^^^^^^
KeyError: 'target_position_ids'
[2025-02-13 06:30:02,349][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 06:30:02,349][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 06:30:02,350][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 06:30:02,350][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 06:30:02,437][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 06:30:02,447][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: null
  checkpoint_per_steps: null
  max_eval_steps: -1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 06:30:45,071][__main__][ERROR] - An error occurred in hydra_main: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1417, in run_train
    prediction = self.forward(
                 ^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 971, in forward
    loss_weight[is_causal, :] = causal_loss_weight
    ~~~~~~~~~~~^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[2025-02-13 06:32:47,954][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 06:32:47,954][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 06:32:47,954][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 06:32:47,954][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 06:32:48,091][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 06:32:48,100][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: null
  checkpoint_per_steps: null
  max_eval_steps: -1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 06:36:09,427][__main__][ERROR] - An error occurred in hydra_main: 
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1419, in run_train
    base_input_ids=batch["base_input_ids"],
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 971, in forward
    loss_weight[is_causal, :] = causal_loss_weight
    ^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
[2025-02-13 06:36:31,607][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 06:36:31,608][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 06:36:31,608][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 06:36:31,608][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 06:36:31,741][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 06:36:31,752][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: null
  checkpoint_per_steps: null
  max_eval_steps: -1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 06:37:12,277][__main__][ERROR] - An error occurred in hydra_main: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 235, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 180, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1417, in run_train
    prediction = self.forward(
                 ^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 949, in forward
    _pred: InterpretorModelOutput = self.interpretor(
                                    ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/modules.py", line 867, in forward
    target_result = self.target_model(
                    ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/gemma/modeling_gemma.py", line 1069, in forward
    outputs = self.model(
              ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/transformers/models/gemma/modeling_gemma.py", line 881, in forward
    layer_outputs = decoder_layer(
                    ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1845, in _call_impl
    return inner()
           ^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1806, in inner
    hook_result = hook(self, args, result)
                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/modules.py", line 847, in representation_swap
    mixed_output, metrics = self._apply_intervention(
                            ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/modules.py", line 687, in _apply_intervention
    intervention_output = self.das_module(
                          ^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/reft_utils.py", line 231, in forward
    intervention_states = base[batch_indices, intervention_positions].unsqueeze(
                          ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA error: device-side assert triggered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[2025-02-13 06:40:07,964][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-13 06:40:07,965][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-13 06:40:07,965][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-13 06:40:07,965][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-13 06:40:08,099][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-13 06:40:08,109][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: null
  checkpoint_per_steps: null
  max_eval_steps: -1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: ${oc.env:WANDB_PROJECT,"HyperDAS"}
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-13 06:40:48,598][src.hyperdas.llama3.model][INFO] - {'counters/step': 0, 'counters/epoch': 0.0, 'train_batch_prediction_loss': 2.4985620975494385, 'grad_norm': 124.0}
[2025-02-13 06:40:48,637][src.hyperdas.llama3.model][INFO] - Training stopped. Reached max steps.
[2025-02-14 22:47:06,708][__main__][INFO] - Working directory : /workspace/HyperDAS
[2025-02-14 22:47:06,709][__main__][INFO] - Original working directory    : /workspace/HyperDAS
[2025-02-14 22:47:06,709][__main__][INFO] - to_absolute_path('foo')       : /workspace/HyperDAS/foo
[2025-02-14 22:47:06,709][__main__][INFO] - to_absolute_path('/foo')      : /foo
[2025-02-14 22:47:06,840][__main__][INFO] - Running in parallel mode on device cuda:0
[2025-02-14 22:47:06,849][__main__][INFO] - Config: model:
  name_or_path: TinyLlama/TinyLlama_v1.1
  target_model_name_or_path: google/gemma-2b
  initialize_from_scratch: false
  intervention_layer:
  - 10
  das_dimension: 32
  num_editing_heads: 32
  num_decoders: 8
  subspace_module: LoReFT
  dict_size: null
  selection_mechanism: null
  orthogonal_init: false
  ridge_parameterization: null
  scoring_dimension: 8
  return_penalty: false
  freeze_das_module: false
  inference_modes:
  - default
  lambda_parameter: 0.001
  ablate_base_token_attention: false
  ablate_source_token_attention: false
  break_asymmetric: false
  importance_power: -2
  epsilon: 1.0e-06
  hat_matrix: false
  max_length: 1024
  sampling:
    max_new_tokens: 128
    temperature: 0.7
    do_sample: true
  judge_model: gpt-4o-mini-2024-07-18
  baseline_model: PromptSteering
  intepretor_type: reft
  hypernetwork_type: steering
  chop_editor_at_layer: 15
  target_hidden_size: 2048
  intervention_positions: f7+l7
dataset:
  source_suffix_visibility: false
  base_suffix_visibility: false
  dataset_type: axbench
  mode: localization
  train_ratio: 0.8
  train_path: experiments/axbench/concept10_2b_l10
  test_path: experiments/axbench/concept10_2b_l10
  axbench_mode: steering
  split_by: concept
training:
  n_epochs: 1
  n_steps: 1
  train_batch_size: 4
  test_batch_size: 64
  lr: 0.0001
  eval_per_steps: null
  checkpoint_per_steps: null
  max_eval_steps: 1
  num_workers: 0
  seed: 42
  save_dir: assets/checkpoints
  compute_metrics: true
  debug_model: true
  save_model: true
  max_grad_norm: 4.0
  weight_decay: 0.01
  rotate_lr: 0.001
  boundary_lr: 0.01
  das_temperature_start: 50.0
  das_temperature_end: 0.1
  load_trained_from: null
  target_intervention_num: null
loss:
  causal_loss_weight: 3.5
  iso_loss_weight: 1.0
  source_selection_sparsity_loss: false
  target_intervention_num: null
  sparsity:
    apply: false
    weight: 1.0
  return_penalty: false
wandb_config:
  log: false
  project: HyperReFT_Steering
  entity: ${oc.env:WANDB_ENTITY,null}
  run_name: ${oc.env:WANDB_RUN_NAME,null}
  group: llama38b_gemma2b_hyperloreft_steer
  tags: ${oc.env:WANDB_TAGS,null}
  notes: ${oc.env:WANDB_NOTES,null}

[2025-02-14 22:47:46,215][src.hyperdas.llama3.model][INFO] - {'counters/step': 0, 'counters/epoch': 0.0, 'train_batch_prediction_loss': 2.4985620975494385, 'grad_norm': 124.0}
[2025-02-14 22:47:46,254][src.hyperdas.llama3.model][INFO] - Training stopped. Reached max steps.
[2025-02-14 22:47:53,521][src.hyperdas.llama3.model][DEBUG] - 
Stopping early at 1 steps
[2025-02-14 22:47:53,522][src.hyperdas.llama3.model][INFO] - 
Completed generation for 128 examples
[2025-02-14 22:47:53,569][axbench.evaluators.lm_judge][WARNING] - Starting task for concept_id: None, model: TinyLlama/TinyLlama_v1.1, evaluator: LMJudgeEvaluator
[2025-02-14 22:47:54,672][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,769][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,782][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,789][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,800][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,804][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,810][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,815][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,852][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,915][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,926][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,941][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,961][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:54,985][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,048][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,103][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,148][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,174][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,192][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,199][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,436][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,457][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,541][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,598][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,732][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,915][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:55,997][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:56,100][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:56,422][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:56,888][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:47:57,583][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:42,677][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:43,835][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:43,837][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:43,969][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,015][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,047][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,051][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,063][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,081][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,126][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,154][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,167][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,168][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,203][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,207][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,309][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,335][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,408][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,755][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:44,837][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:45,857][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:48:59,506][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:38,115][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:39,048][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:39,345][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:39,351][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:39,365][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:39,605][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:39,839][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:39,936][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:39,951][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:39,952][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:40,219][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:40,248][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:40,308][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:40,311][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:40,353][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:40,740][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:40,788][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:40,900][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:41,112][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:42,203][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:42,283][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:42,345][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:42,637][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:42,646][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:42,728][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:42,735][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:42,774][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:43,022][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:43,032][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:43,058][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:43,071][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:43,123][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:43,216][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:44,152][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:44,515][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:45,460][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:47,784][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,003][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,045][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,091][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,121][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,194][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,207][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,220][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,265][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,368][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,441][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,519][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,684][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,686][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,690][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,694][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,755][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,759][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,785][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:49,912][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:50,020][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:50,432][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:50,543][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:51,747][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:51,750][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:52,028][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:52,060][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:52,121][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:52,204][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:52,217][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:52,246][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:52,301][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:52,356][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:53,812][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:53,841][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:53,858][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:53,929][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:53,973][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,007][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,045][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,052][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,071][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,078][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,098][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,118][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,126][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,147][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,178][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,191][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,234][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,237][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,259][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,394][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,510][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,650][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,675][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,727][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,779][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:54,843][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:55,222][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:55,535][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:56,365][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:56,487][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:56,584][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:49:59,423][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:00,847][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:00,874][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:00,883][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:00,924][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:00,959][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,106][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,138][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,168][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,175][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,179][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,185][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,185][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,194][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,225][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,343][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,388][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,465][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,466][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,500][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,548][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,557][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,582][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,587][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,591][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,752][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,853][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:01,870][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:02,403][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:04,026][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:04,509][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:04,594][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:06,461][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:07,592][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:07,753][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:07,763][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:07,773][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:07,821][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:07,896][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:07,947][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,027][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,032][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,043][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,054][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,095][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,105][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,127][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,174][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,192][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,256][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,258][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,284][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,419][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,420][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,429][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,431][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,474][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,478][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,695][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,834][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:08,969][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:09,060][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:09,114][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:09,328][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:11,861][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:12,712][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:12,778][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:12,901][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,022][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,102][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,120][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,174][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,205][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,206][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,234][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,261][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,394][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,484][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,562][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,600][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,629][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,638][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,654][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,671][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,687][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,742][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,876][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,902][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,959][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:13,995][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:14,082][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:14,182][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:14,210][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:14,351][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:14,666][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:14,847][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:14,956][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:16,707][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:16,947][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:17,074][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:17,105][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:17,253][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:17,265][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:17,333][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:17,937][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:18,012][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:18,227][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:18,411][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:18,729][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:18,734][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:18,956][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:20,590][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:21,127][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:21,236][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:21,287][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:21,429][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:21,470][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:21,643][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:21,644][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:21,915][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:22,047][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:22,143][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:24,799][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:26,002][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:26,574][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:28,376][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:28,385][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:28,507][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:28,726][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:28,729][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:28,758][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:28,795][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:28,889][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:28,999][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:29,039][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:29,119][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:29,263][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:29,745][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:31,532][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:31,537][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:50:31,537][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:50:31,537][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment so I can assess its fluency.
[2025-02-14 22:50:31,537][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:50:31,537][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:50:31,538][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment so I can assess its fluency.
[2025-02-14 22:50:31,538][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment so I can assess its fluency.
[2025-02-14 22:50:31,538][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment so I can assess its fluency.
[2025-02-14 22:50:31,538][axbench.evaluators.lm_judge][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:50:32,710][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:32,845][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:32,854][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:32,875][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:32,877][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:32,914][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,023][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,103][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,220][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,231][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,278][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,284][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,409][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,465][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,469][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,480][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,559][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,681][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,817][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:33,859][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:34,337][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:34,353][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:34,499][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:36,789][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,078][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,088][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,135][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,160][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,235][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,272][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,279][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,291][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,299][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,308][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,317][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,321][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,323][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,342][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,347][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,369][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,371][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,389][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,561][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,577][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,593][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,596][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,614][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,617][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,649][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,693][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,775][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:38,874][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:39,227][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:40,302][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:41,670][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:41,671][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:41,697][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:41,719][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:41,753][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:41,775][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:41,797][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:41,806][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:41,932][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,004][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,016][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,039][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,051][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,069][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,091][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,109][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,240][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,272][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,277][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,324][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,325][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,361][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,432][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,459][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,509][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,520][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,544][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,589][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,595][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:42,803][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:43,167][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:43,178][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,530][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,627][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,647][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,652][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,666][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,681][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,707][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,735][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,770][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,785][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,786][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,800][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,801][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,821][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,879][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,911][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:44,938][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,025][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,078][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,086][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,096][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,129][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,149][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,173][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,267][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,273][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,304][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,354][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,438][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:45,514][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:46,335][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:48,836][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,019][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,074][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,214][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,234][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,309][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,322][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,350][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,375][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,410][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,418][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,438][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,452][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,549][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,706][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,715][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,728][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,862][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:50,921][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:51,000][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:51,168][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:51,307][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:51,348][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:51,391][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:51,443][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:51,478][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:51,886][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:51,993][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:54,519][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,009][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,068][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,149][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,166][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,178][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,207][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,250][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,252][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,252][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,263][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,271][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,281][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,287][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,298][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,438][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,473][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,484][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,490][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,572][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,584][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,701][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,765][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,774][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,861][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,926][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:56,995][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:50:57,197][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:00,321][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:00,393][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:01,136][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,422][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,453][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,587][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,715][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,737][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,763][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,798][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,812][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,826][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,836][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,863][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,953][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:02,974][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,014][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,031][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,039][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,047][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,083][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,105][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,297][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,325][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,360][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,362][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,368][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,425][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,476][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,511][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,524][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,570][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,636][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:03,782][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:04,134][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:05,681][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:05,730][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:05,785][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:05,819][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:05,828][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:05,880][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:05,893][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:05,968][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,035][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,042][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,044][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,076][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,098][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,121][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,173][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,190][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,192][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,247][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,273][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,283][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,341][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,371][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,400][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,444][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,503][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,561][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,563][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,578][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:06,684][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:07,793][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:08,727][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:09,137][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:10,199][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:10,289][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:10,595][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:10,687][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:10,921][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:10,938][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:11,014][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:11,070][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:11,200][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:11,254][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:11,296][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:11,420][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:11,802][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:11,857][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:11,870][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:11,936][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:11,941][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:12,032][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:12,146][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:12,301][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:12,611][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:12,708][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:14,469][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:14,553][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:14,603][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:14,649][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:14,754][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:14,798][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:14,828][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:14,965][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:14,969][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,072][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,080][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,116][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,149][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,158][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,257][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,321][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,354][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,437][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,784][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,946][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,990][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:15,998][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:16,340][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:16,818][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:16,856][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:16,942][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:16,970][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:17,108][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:17,368][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:17,418][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:18,924][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,026][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,196][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,250][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,256][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,274][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,322][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,346][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,383][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,394][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,462][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,520][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,579][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,582][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,614][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,665][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,717][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,719][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,774][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:19,837][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:20,013][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:20,017][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:20,025][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:20,042][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:20,050][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:20,153][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:20,161][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:20,257][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:20,333][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:20,468][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:20,496][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:21,328][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:22,868][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:22,919][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:22,990][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,164][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,254][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,261][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,298][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,307][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,319][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,373][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,384][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,424][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,448][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,488][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,495][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,508][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,538][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,555][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,580][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,640][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,824][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,941][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:23,947][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:24,043][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:24,049][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:24,208][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:24,491][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:24,762][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:24,766][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:26,603][httpx][INFO] - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
[2025-02-14 22:51:26,613][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,613][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,613][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,614][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,614][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment so I can assess its fluency.
[2025-02-14 22:51:26,614][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment so I can assess its fluency.
[2025-02-14 22:51:26,614][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,614][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,614][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,614][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,614][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,615][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,624][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,625][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,625][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment so I can assess its fluency.
[2025-02-14 22:51:26,625][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,625][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,625][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment so I can assess its fluency.
[2025-02-14 22:51:26,625][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment so I can assess its fluency.
[2025-02-14 22:51:26,625][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment so I can assess its fluency.
[2025-02-14 22:51:26,626][axbench.evaluators.winrate][WARNING] - Cannot find rating value: It appears that there is no sentence fragment provided for evaluation. Please provide a sentence fragment for me to assess its fluency.
[2025-02-14 22:51:26,626][__main__][ERROR] - An error occurred in hydra_main: 'concept_id'
Traceback (most recent call last):
  File "/workspace/HyperDAS/train.py", line 234, in main
    run_experiment(cfg, device)
  File "/workspace/HyperDAS/train.py", line 179, in run_experiment
    hypernetwork.run_train(train_loader=train_data_loader, test_loader=test_data_loader)
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1483, in run_train
    result_dict[tl.name] = self.eval_accuracy(
                           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/HyperDAS/src/hyperdas/llama3/model.py", line 1276, in eval_accuracy
    for concept_id, concept_data in eval_df.groupby("concept_id"):
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py", line 9183, in groupby
    return DataFrameGroupBy(
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pandas/core/groupby/groupby.py", line 1329, in __init__
    grouper, exclusions, obj = get_grouper(
                               ^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/pandas/core/groupby/grouper.py", line 1043, in get_grouper
    raise KeyError(gpr)
KeyError: 'concept_id'

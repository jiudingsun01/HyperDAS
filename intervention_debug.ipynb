{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/sjd24/miniconda3/envs/hypernet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "\n",
    "from src.hyperdas.data_utils import (\n",
    "    filter_dataset,\n",
    "    generate_ravel_dataset,\n",
    "    get_ravel_collate_fn,\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/scr-ssd/sjd24/llama3-8b\")\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "train_dataset = load_from_disk(\"./experiments/RAVEL/data/city_country_train\")\n",
    "test_dataset = load_from_disk(\"./experiments/RAVEL/data/city_country_test\")\n",
    "\n",
    "collate_fn = get_ravel_collate_fn(\n",
    "    tokenizer,\n",
    "    add_space_before_target=True,\n",
    "    contain_entity_position=True,\n",
    "    source_suffix_visibility=False,\n",
    "    base_suffix_visibility=False,\n",
    ")\n",
    "dataloader = DataLoader(\n",
    "    test_dataset, batch_size=16, collate_fn=collate_fn, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.21it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.64it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/tmp/user/24141/ipykernel_1057699/3084088035.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(os.path.join(\"/nlp/scr/sjd24/MDAS_dimension/ravel_mdas_128_country\", \"final_das_module.pt\"))\n",
      "/tmp/user/24141/ipykernel_1057699/3084088035.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  hypernetwork.interpretor.hypernetwork.load_state_dict(torch.load(os.path.join(f\"/nlp/scr/sjd24/HyperDAS_layers/ravel_layer_15/final_model\", \"hypernetwork.pt\")))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.hyperdas.llama3.model import RavelInterpretorHypernetwork\n",
    "\n",
    "hypernetwork = RavelInterpretorHypernetwork(\n",
    "    model_name_or_path=\"/scr-ssd/sjd24/llama3-8b\",\n",
    "    num_editing_heads=32,\n",
    "    intervention_layer=15,\n",
    "    subspace_module=\"DAS\",\n",
    "    das_dimension=128,\n",
    ")\n",
    "hypernetwork = hypernetwork.to(\"cuda\")\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "state_dict = torch.load(\n",
    "    os.path.join(\n",
    "        \"/nlp/scr/sjd24/MDAS_dimension/ravel_mdas_128_country\", \"final_das_module.pt\"\n",
    "    )\n",
    ")\n",
    "state_dict.pop(\"embed_dim\")\n",
    "state_dict.pop(\"interchange_dim\")\n",
    "\n",
    "hypernetwork.interpretor.hypernetwork.load_state_dict(\n",
    "    torch.load(\n",
    "        os.path.join(\n",
    "            f\"/nlp/scr/sjd24/HyperDAS_layers/ravel_layer_15/final_model\",\n",
    "            \"hypernetwork.pt\",\n",
    "        )\n",
    "    )\n",
    ")\n",
    "hypernetwork.interpretor.das_module.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/user/24141/ipykernel_1057699/4074144641.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  intervenable.interventions[intervention_key][0].load_state_dict(torch.load(os.path.join(\"/nlp/scr/sjd24/MDAS_dimension/ravel_mdas_128_country\", \"final_das_module.pt\")))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvene import (\n",
    "    IntervenableConfig,\n",
    "    IntervenableModel,\n",
    "    LowRankRotatedSpaceIntervention,\n",
    "    RepresentationConfig,\n",
    "    count_parameters,\n",
    ")\n",
    "\n",
    "intervention_config = IntervenableConfig(\n",
    "    model_type=type(hypernetwork.interpretor.target_model),\n",
    "    representations=[\n",
    "        RepresentationConfig(\n",
    "            15,  # layer\n",
    "            \"block_output\",  # intervention repr\n",
    "            \"pos\",  # intervention unit\n",
    "            1,  # max number of unit\n",
    "            128,\n",
    "        )\n",
    "    ],\n",
    "    intervention_types=LowRankRotatedSpaceIntervention,\n",
    ")\n",
    "\n",
    "intervenable = IntervenableModel(\n",
    "    intervention_config, hypernetwork.interpretor.target_model\n",
    ")\n",
    "intervenable.set_device(hypernetwork.interpretor.target_model.device)\n",
    "intervenable.disable_model_gradients()\n",
    "\n",
    "intervention_key = list(intervenable.interventions.keys())[0]\n",
    "intervenable.interventions[intervention_key][0].load_state_dict(\n",
    "    torch.load(\n",
    "        os.path.join(\n",
    "            \"/nlp/scr/sjd24/MDAS_dimension/ravel_mdas_128_country\",\n",
    "            \"final_das_module.pt\",\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(\n",
    "    base_input_ids: torch.Tensor = None,\n",
    "    base_attention_mask: torch.Tensor = None,\n",
    "    base_intervention_position: torch.Tensor = None,\n",
    "    base_position_ids: torch.Tensor = None,\n",
    "    source_input_ids: torch.Tensor = None,\n",
    "    source_attention_mask: torch.Tensor = None,\n",
    "    source_intervention_position: torch.Tensor = None,\n",
    "    source_position_ids: torch.Tensor = None,\n",
    "    intervention_layer: int = None,\n",
    "):\n",
    "    if intervention_layer is None:\n",
    "        raise ValueError(\"intervention_layer must be specified\")\n",
    "\n",
    "    if base_position_ids is None:\n",
    "        # 0 for all the padding tokens and start from 1 for the rest\n",
    "        base_position_ids = (\n",
    "            torch.cumsum(base_attention_mask, dim=1) * base_attention_mask - 1\n",
    "        )\n",
    "\n",
    "    if source_position_ids is None:\n",
    "        source_position_ids = (\n",
    "            torch.cumsum(source_attention_mask, dim=1) * source_attention_mask - 1\n",
    "        )\n",
    "\n",
    "    # print(source_intervention_position.unsqueeze(0).shape, base_intervention_position.unsqueeze(0).shape)\n",
    "    b_s = base_input_ids.shape[0]\n",
    "    intervention_locations = {\n",
    "        \"sources->base\": (\n",
    "            source_intervention_position.unsqueeze(0).unsqueeze(-1),\n",
    "            base_intervention_position.unsqueeze(0).unsqueeze(-1),\n",
    "        )\n",
    "    }\n",
    "\n",
    "    _, counterfactual_outputs = intervenable(\n",
    "        {\n",
    "            \"input_ids\": base_input_ids,\n",
    "            \"attention_mask\": base_attention_mask,\n",
    "            \"position_ids\": base_position_ids,\n",
    "        },\n",
    "        [\n",
    "            {\n",
    "                \"input_ids\": source_input_ids,\n",
    "                \"attention_mask\": source_attention_mask,\n",
    "                \"position_ids\": source_position_ids,\n",
    "            }\n",
    "        ],\n",
    "        intervention_locations,\n",
    "        output_original_output=True,\n",
    "    )\n",
    "\n",
    "    return counterfactual_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['editor_input_ids', 'is_causal', 'base_input_ids', 'base_attention_mask', 'base_intervention_mask', 'source_input_ids', 'source_attention_mask', 'source_intervention_mask', 'labels', 'source_entity_position_ids', 'base_entity_position_ids'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor_input_ids = batch[\"editor_input_ids\"].to(\"cuda\")\n",
    "is_causal = batch[\"is_causal\"].to(\"cuda\")\n",
    "\n",
    "base_intervention_position = batch[\"base_entity_position_ids\"].to(\"cuda\")\n",
    "source_intervention_position = batch[\"source_entity_position_ids\"].to(\"cuda\")\n",
    "\n",
    "base_input_ids = batch[\"base_input_ids\"].to(\"cuda\")\n",
    "base_attention_mask = batch[\"base_attention_mask\"].to(\"cuda\")\n",
    "base_intervention_mask = batch[\"base_intervention_mask\"].to(\"cuda\")\n",
    "\n",
    "source_input_ids = batch[\"source_input_ids\"].to(\"cuda\")\n",
    "source_attention_mask = batch[\"source_attention_mask\"].to(\"cuda\")\n",
    "source_intervention_mask = batch[\"source_intervention_mask\"].to(\"cuda\")\n",
    "\n",
    "labels = batch[\"labels\"].to(\"cuda\")\n",
    "\n",
    "intervention_weight = torch.zeros(\n",
    "    len(batch[\"editor_input_ids\"]),\n",
    "    batch[\"source_input_ids\"].shape[1] + 1,\n",
    "    batch[\"base_input_ids\"].shape[1],\n",
    ").to(\"cuda\")\n",
    "intervention_weight[:, -1, :] = 1.0\n",
    "\n",
    "for i in range(len(batch[\"base_entity_position_ids\"])):\n",
    "    intervention_weight[i, -1, batch[\"base_entity_position_ids\"][i]] = 0.0\n",
    "    intervention_weight[\n",
    "        i, batch[\"source_entity_position_ids\"][i], batch[\"base_entity_position_ids\"][i]\n",
    "    ] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 29, 4096])\n",
      "tensor([-0.0096,  0.0107, -0.0063,  ...,  0.0110,  0.0236,  0.0074],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "mdas_output = forward(\n",
    "    base_input_ids=base_input_ids,\n",
    "    base_attention_mask=base_attention_mask,\n",
    "    base_intervention_position=base_intervention_position,\n",
    "    source_input_ids=source_input_ids,\n",
    "    source_attention_mask=source_attention_mask,\n",
    "    source_intervention_position=source_intervention_position,\n",
    "    intervention_layer=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.\n",
      "torch.Size([16, 29, 33, 4096])\n",
      "tensor([-0.0060,  0.0381, -0.0095,  ...,  0.0767, -0.0615,  0.0269],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hypernet_output \u001b[38;5;241m=\u001b[39m \u001b[43mhypernetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43meditor_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meditor_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_intervention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_intervention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource_intervention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_intervention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_intervention_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgroundtruth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintervention_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintervention_weight\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/sailhome/sjd24/HyperDAS/src/hyperdas/llama3/model.py:101\u001b[0m, in \u001b[0;36mRavelInterpretorHypernetwork.forward\u001b[0;34m(self, editor_input_ids, base_input_ids, base_attention_mask, base_intervention_mask, source_input_ids, source_attention_mask, source_intervention_mask, labels, output_intervention_weight, is_causal, causal_loss_weight, iso_loss_weight, intervention_weight, inference_mode)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     86\u001b[0m     editor_input_ids: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m     inference_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    100\u001b[0m ):\n\u001b[0;32m--> 101\u001b[0m     _pred: InterpretorModelOutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpretor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43meditor_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meditor_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43meditor_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meditor_input_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpretor_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_intervention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_intervention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_intervention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_intervention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_intervention_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_intervention_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintervention_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintervention_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_mode\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         log_prob_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlog_softmax(\n\u001b[1;32m    117\u001b[0m             _pred\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, _pred\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m    118\u001b[0m             dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    119\u001b[0m         )\n",
      "File \u001b[0;32m/nlp/scr/sjd24/miniconda3/envs/hypernet/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nlp/scr/sjd24/miniconda3/envs/hypernet/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/sailhome/sjd24/HyperDAS/src/hyperdas/llama3/modules.py:549\u001b[0m, in \u001b[0;36mLlamaInterpretor.forward\u001b[0;34m(self, editor_input_ids, editor_attention_mask, base_input_ids, base_attention_mask, base_intervention_mask, source_input_ids, source_attention_mask, source_intervention_mask, base_hidden_states, base_position_ids, source_hidden_states, source_position_ids, intervention_layer, output_vanilla_hidden_states, output_edited_hidden_states, output_intervention_weight, intervention_weight, inference_mode)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28mprint\u001b[39m(base_hidden_states\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28mprint\u001b[39m(base_hidden_states[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m23\u001b[39m, \u001b[38;5;241m15\u001b[39m])\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    550\u001b[0m base_normalization_factors \u001b[38;5;241m=\u001b[39m base_hidden_states\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    551\u001b[0m base_hidden_states \u001b[38;5;241m=\u001b[39m base_hidden_states \u001b[38;5;241m/\u001b[39m base_normalization_factors\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "hypernet_output = hypernetwork.forward(\n",
    "    editor_input_ids=editor_input_ids,\n",
    "    base_input_ids=base_input_ids,\n",
    "    base_attention_mask=base_attention_mask,\n",
    "    base_intervention_mask=base_intervention_mask,\n",
    "    source_input_ids=source_input_ids,\n",
    "    source_attention_mask=source_attention_mask,\n",
    "    source_intervention_mask=source_intervention_mask,\n",
    "    labels=labels,\n",
    "    output_intervention_weight=True,\n",
    "    inference_mode=\"groundtruth\",\n",
    "    intervention_weight=intervention_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.7500, -2.8594, -3.5469,  ...,  5.0312,  5.0312,  5.0312],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypernet_output.logits[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.7500, -2.8750, -3.4531,  ...,  5.0000,  5.0000,  5.0000],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdas_output.logits[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt_output = hypernetwork.interpretor.target_model(\n",
    "    input_ids=base_input_ids,\n",
    "    attention_mask=base_attention_mask,\n",
    "    position_ids=torch.cumsum(base_attention_mask, dim=1) * base_attention_mask - 1,\n",
    "    return_dict=True,\n",
    "    output_hidden_states=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 29])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0060,  0.0381, -0.0095,  ...,  0.0767, -0.0615,  0.0269],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_prompt_output.hidden_states[15][0, 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 29, 128256])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hyperdas.data_utils import (\n",
    "    filter_dataset,\n",
    "    generate_ravel_dataset,\n",
    "    get_ravel_collate_fn,\n",
    ")\n",
    "\n",
    "dataset = generate_ravel_dataset(\n",
    "    1000,\n",
    "    root_path=\"./data/RAVEL\",\n",
    "    target_attributes=[\"Country\"],\n",
    "    isolate_attributes=[\"Continent\"],\n",
    "    template_split=\"train\",\n",
    "    entity_split=\"both\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:02, 24.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.811; filtered out 189 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_prefix', 'input_suffix', 'counterfactual_input_prefix', 'counterfactual_input_suffix', 'edit_instruction', 'entity', 'counterfactual_entity', 'target', 'counterfactual_target', 'attribute_type', 'domain', 'attribute', 'verify_text'],\n",
       "    num_rows: 811\n",
       "})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_dataset(\n",
    "    hypernetwork.interpretor.target_model, tokenizer, dataset, relative_position=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "63it [00:02, 26.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81; filtered out 190 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_prefix', 'input_suffix', 'counterfactual_input_prefix', 'counterfactual_input_suffix', 'edit_instruction', 'entity', 'counterfactual_entity', 'target', 'counterfactual_target', 'attribute_type', 'domain', 'attribute', 'verify_text'],\n",
       "    num_rows: 810\n",
       "})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_dataset(\n",
    "    hypernetwork.interpretor.target_model,\n",
    "    tokenizer,\n",
    "    dataset,\n",
    "    relative_position_ids=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypernet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

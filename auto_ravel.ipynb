{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get All Domains in Wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from json import JSONDecodeError\n",
    "from time import sleep\n",
    "import re\n",
    "from urllib.parse import unquote, urlparse\n",
    "import openai\n",
    "import asyncio\n",
    "\n",
    "url = \"https://query.wikidata.org/sparql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_entites(qid, limit=10000):\n",
    "    query = f\"\"\"\n",
    "        SELECT ?entity ?entityLabel\n",
    "        WHERE {{\n",
    "            ?entity wdt:P31 wd:{qid}.\n",
    "            ?entity rdfs:label ?entityLabel filter (lang(?entityLabel) = \"en\")\n",
    "        }}\n",
    "        LIMIT {limit}\n",
    "    \"\"\"\n",
    "    r = requests.get(url, params={\"format\": \"json\", \"query\": query})\n",
    "    try:\n",
    "        data = r.json()\n",
    "    except JSONDecodeError:\n",
    "        sleep(5)\n",
    "        r = requests.get(url, params={\"format\": \"json\", \"query\": query})\n",
    "        data = r.json()\n",
    "\n",
    "    entities = dict()\n",
    "\n",
    "    for e in data[\"results\"][\"bindings\"]:\n",
    "        entity_id = e[\"entity\"][\"value\"].split(\"/\")[-1]\n",
    "        entity_label = e[\"entityLabel\"][\"value\"]\n",
    "        entities[entity_id] = entity_label\n",
    "\n",
    "    return entities\n",
    "\n",
    "\n",
    "def get_entity_attributes(qid, retries=0):\n",
    "    query = f\"\"\"\n",
    "        SELECT ?property ?propertyLabel ?value ?valueLabel\n",
    "        WHERE {{\n",
    "            wd:{qid} ?p ?value .\n",
    "            ?property wikibase:directClaim ?p .\n",
    "            SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "        }}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        r = requests.get(url, params={\"format\": \"json\", \"query\": query})\n",
    "        data = r.json()\n",
    "    except JSONDecodeError:\n",
    "        asyncio.sleep(5)\n",
    "        r = requests.get(url, params={\"format\": \"json\", \"query\": query})\n",
    "        data = r.json()\n",
    "    except requests.ConnectTimeout:\n",
    "        if retries > 5:\n",
    "            raise KeyError\n",
    "        asyncio.sleep(5)\n",
    "        return get_entity_attributes(qid, retries + 1)\n",
    "\n",
    "    properties = dict()\n",
    "\n",
    "    for p in data[\"results\"][\"bindings\"]:\n",
    "        property_id = p[\"property\"][\"value\"].split(\"/\")[-1]\n",
    "        property_label = p[\"propertyLabel\"][\"value\"]\n",
    "        value_label = p[\"valueLabel\"][\"value\"]\n",
    "\n",
    "        if property_id.startswith(\"P\"):\n",
    "            properties[property_id] = (property_label, value_label)\n",
    "\n",
    "    return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_content(url):\n",
    "    # Extracting the title from the URL\n",
    "    parsed_url = urlparse(url)\n",
    "    title = unquote(parsed_url.path.split(\"/\")[-1])\n",
    "\n",
    "    # API request setup\n",
    "    api_url = f\"https://{parsed_url.netloc}/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"titles\": title,\n",
    "        \"prop\": \"extracts\",\n",
    "        \"explaintext\": True,\n",
    "    }\n",
    "\n",
    "    # Making the request\n",
    "    try:\n",
    "        response = requests.get(api_url, params=params)\n",
    "    except requests.exceptions.InvalidURL:\n",
    "        print(\"Invalid URL\")\n",
    "        print(parsed_url.netloc)\n",
    "        raise\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    # Extracting the page content\n",
    "    page = next(iter(data[\"query\"][\"pages\"].values()))\n",
    "    if \"extract\" in page:\n",
    "        return page[\"extract\"]\n",
    "    else:\n",
    "        return \"Article content not found.\"\n",
    "\n",
    "\n",
    "def get_wikipedia_sentences(\n",
    "    content, entity_name, word_upper_limit=20, word_lower_limit=5\n",
    "):\n",
    "    # Splitting the content into sentences by \". \", \".\\n\" or \".\\t\"\n",
    "    sentences = [s.strip() for s in re.split(r\"\\.|\\;|\\,|\\n|\\!|\\?\", content)]\n",
    "\n",
    "    # Filtering the sentences that mention the entity\n",
    "    entity_sentences = [s for s in sentences if entity_name in s]\n",
    "\n",
    "    # Filtering the sentences by word count\n",
    "    entity_sentences = [\n",
    "        s\n",
    "        for s in entity_sentences\n",
    "        if len(s.split()) <= word_upper_limit and len(s.split()) >= word_lower_limit\n",
    "    ]\n",
    "\n",
    "    return entity_sentences\n",
    "\n",
    "\n",
    "def get_wikipedia_url(wikidata_id, language=\"en\"):\n",
    "    # Constructing the URL to call the API\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"wbgetentities\",\n",
    "        \"ids\": wikidata_id,\n",
    "        \"format\": \"json\",\n",
    "        \"props\": \"sitelinks\",\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    # Accessing the sitelink for the specified language\n",
    "    try:\n",
    "        wikipedia_title = data[\"entities\"][wikidata_id][\"sitelinks\"][f\"{language}wiki\"][\n",
    "            \"title\"\n",
    "        ]\n",
    "        wikipedia_url = (\n",
    "            f\"https://{language}.wikipedia.org/wiki/{wikipedia_title.replace(' ', '_')}\"\n",
    "        )\n",
    "        return wikipedia_url\n",
    "    except KeyError:\n",
    "        return \"No Wikipedia article found for this language.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "\n",
    "async def filter_attribute(attribute, retries=0):\n",
    "    client = AsyncOpenAI(\n",
    "        # This is the default and can be omitted\n",
    "        api_key=\"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\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        chat_completion = await client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Classify the following attribute into 'common knowledge' or 'specialized'.\\nExamples of common knowledge attribute: Cause of death, Nationality, category for people buried here, Country of origin\\nExamples of specialized attribute: image of grave, Canadiana Name Authority ID, Diamond Catalog ID for persons and organisations\\n\\n\\n\"\n",
    "                    + \"Attribute\"\n",
    "                    + attribute\n",
    "                    + \"\\n\\nClass: \",\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "        )\n",
    "    except openai.APIConnectionError:\n",
    "        if retries >= 5:\n",
    "            print(f\"Max retries reached. Skipping attribute {attribute}\")\n",
    "            return \"specialized\"\n",
    "\n",
    "        print(\"GPT-3.5 Timeout. Sleep for 5 seconds\")\n",
    "        asyncio.sleep(5)\n",
    "        return filter_attribute(attribute, retries + 1)\n",
    "\n",
    "    # OpenAI API Key setup\n",
    "    content = chat_completion.choices[0].message.content\n",
    "    return content\n",
    "\n",
    "\n",
    "async def filter_attributes(attributes):\n",
    "    filtered_attributes = dict()\n",
    "\n",
    "    # Prepare a list of tasks for asynchronous execution\n",
    "    tasks = [\n",
    "        asyncio.create_task(filter_attribute(attributes[attribute][0]))\n",
    "        for attribute in attributes\n",
    "    ]\n",
    "\n",
    "    # Use asyncio.gather to run tasks concurrently and wait for all to complete\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # After tasks complete, map results back to attribute keys\n",
    "    for attribute, result in zip(attributes, results):\n",
    "        filtered_attributes[attribute] = result\n",
    "\n",
    "    is_common_knowledge = dict()\n",
    "    for attribute, pred in filtered_attributes.items():\n",
    "        try:\n",
    "            is_common_knowledge[attribute] = \"specialized\" not in pred.lower()\n",
    "        except AttributeError:\n",
    "            is_common_knowledge[attribute] = False\n",
    "\n",
    "    filtered_attributes = {\n",
    "        k: attributes[k]\n",
    "        for k, v in filtered_attributes.items()\n",
    "        if is_common_knowledge[k]\n",
    "    }\n",
    "\n",
    "    filtered_attributes\n",
    "    return filtered_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "async def get_attribute_prompt(entity_name, context, attribute, label, retries=0):\n",
    "    client = AsyncOpenAI(\n",
    "        # This is the default and can be omitted\n",
    "        api_key=\"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\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        chat_completion = await client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"Given a context sentence about {entity_name}, write a prompt continuing on the context and query the attribute which the model should predict the label in th next token. Following the rules: 1) use co-reference as much as possible to refer to the target entity. 2) Be clear and specific about the target attribute.\",\n",
    "                },\n",
    "                # 1-st example\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Entity: Abraham Lincoln\\n\\nContext: Abraham Lincoln was the 16th president of the United States,\\n\\nAttribute: cause of death\\n\\nLabel: shot to the head\\n\\n\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"Prompt: ' who's cause of death was '\",\n",
    "                },\n",
    "                # 2-nd example\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Entity: A Gang Story\\n\\nContext: A Gang Story (French: Les Lyonnais) is a 2011 French drama film \\n\\nAttribute: screenwriter\\n\\nLabel: Edgar Marie\\n\\n\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"Prompt: ' which was brought to life by the screenwriter '\",\n",
    "                },\n",
    "                # 3-rd example\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Entity: Palo Alto\\n\\nContext: Palo Alto is a charter city in the northwestern corner of Santa Clara County\\n\\nAttribute: country\\n\\nLabel: United States of America\\n\\n\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"Prompt: '; the country that this city belongs to is '\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Entity: {entity_name}\\n\\nContext: {context}\\n\\nAttribute: {attribute}\\n\\nLabel: {label}\\n\\n\",\n",
    "                },\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\",\n",
    "        )\n",
    "    except openai.APIConnectionError:\n",
    "        if retries >= 5:\n",
    "            print(f\"Max retries reached. Skipping attribute {attribute}\")\n",
    "            return None\n",
    "\n",
    "        print(\"GPT-4o Timeout. Sleep for 5 seconds\")\n",
    "        asyncio.sleep(5)\n",
    "        return get_attribute_prompt(entity_name, context, attribute, label, retries + 1)\n",
    "\n",
    "    # OpenAI API Key setup\n",
    "    content = chat_completion.choices[0].message.content\n",
    "    return content\n",
    "\n",
    "\n",
    "async def generate_prompts(entity_name, entity_contexts, attributes, labels):\n",
    "    prompt_dict = dict()\n",
    "\n",
    "    for context in entity_contexts:\n",
    "        prompt_dict[context] = dict()\n",
    "\n",
    "        for attribute, label in zip(attributes, labels):\n",
    "            prompt = await get_attribute_prompt(entity_name, context, attribute, label)\n",
    "\n",
    "            if prompt is None:\n",
    "                continue\n",
    "            prompt = prompt.replace(\"Prompt: \", \"\")[1:-1]\n",
    "\n",
    "            prompt_dict[context][attribute] = (prompt, label)\n",
    "\n",
    "    return prompt_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get Domain Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nlp/scr/sjd24/miniconda3/envs/hypernet/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "async def generate_domain_dataset(\n",
    "    qid,\n",
    "    num_of_context=1,\n",
    "    n_property=5,\n",
    "    limit=1000,\n",
    "    save_per_entity=25,\n",
    "    save_dir=None,\n",
    "    resuming_from=None,\n",
    "):\n",
    "    if save_dir is not None:\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "    domain_dataset = []\n",
    "\n",
    "    idxs_resuming_from = None\n",
    "\n",
    "    if resuming_from is not None:\n",
    "        domain_dataset = Dataset.load_from_disk(resuming_from)\n",
    "        domain_dataset = domain_dataset.to_list()\n",
    "\n",
    "        idxs_resuming_from = len(set([d[\"entity\"] for d in domain_dataset]))\n",
    "\n",
    "    all_entities = get_domain_entites(qid, limit)\n",
    "\n",
    "    print(f\"Number of entities: {len(all_entities)}\")\n",
    "\n",
    "    for i, (entity_qid, entity_name) in enumerate(tqdm(all_entities.items())):\n",
    "        if idxs_resuming_from is not None:\n",
    "            if i < idxs_resuming_from:\n",
    "                print(f\"Skipping entity {i}-th entity\")\n",
    "                continue\n",
    "\n",
    "        if save_per_entity is not None and len(all_entities) > save_per_entity:\n",
    "            if i % save_per_entity == 0 and i != 0:\n",
    "                if save_dir is not None:\n",
    "                    temp = Dataset.from_list(domain_dataset)\n",
    "                    temp.save_to_disk(os.path.join(save_dir, f\"{qid}\"))\n",
    "\n",
    "        attributes = get_entity_attributes(entity_qid)\n",
    "        filtered_attributes = await filter_attributes(attributes)\n",
    "\n",
    "        try:\n",
    "            wikipedia_url = get_wikipedia_url(entity_qid)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        except requests.ConnectTimeout:\n",
    "            asyncio.sleep(5)\n",
    "            wikipedia_url = get_wikipedia_url(entity_qid)\n",
    "            if wikipedia_url is None or wikipedia_url == \"\":\n",
    "                continue\n",
    "        try:\n",
    "            wikipedia_content = get_wikipedia_content(wikipedia_url)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        except requests.exceptions.InvalidURL:\n",
    "            print(wikipedia_url)\n",
    "            raise\n",
    "        except requests.ConnectTimeout:\n",
    "            asyncio.sleep(5)\n",
    "            wikipedia_content = get_wikipedia_content(wikipedia_url)\n",
    "\n",
    "        entity_contexts = get_wikipedia_sentences(wikipedia_content, entity_name)\n",
    "        if len(entity_contexts) == 0 or len(filtered_attributes) == 0:\n",
    "            continue\n",
    "\n",
    "        if num_of_context is None:\n",
    "            entity_contexts = entity_contexts\n",
    "        elif num_of_context == 1:\n",
    "            entity_contexts = [entity_contexts[0]]\n",
    "        elif len(entity_contexts) > num_of_context:\n",
    "            entity_contexts = random.sample(entity_contexts, num_of_context)\n",
    "\n",
    "        if len(filtered_attributes) > n_property:\n",
    "            selected_keys = random.sample(filtered_attributes.keys(), n_property)\n",
    "            filtered_attributes = {k: filtered_attributes[k] for k in selected_keys}\n",
    "\n",
    "        attributes = []\n",
    "        labels = []\n",
    "\n",
    "        for attribute_qid in filtered_attributes.keys():\n",
    "            attribute, value = filtered_attributes[attribute_qid]\n",
    "            attributes.append(attribute)\n",
    "            labels.append(value)\n",
    "\n",
    "        prompt_dict = await generate_prompts(\n",
    "            entity_name, entity_contexts, attributes, labels\n",
    "        )\n",
    "\n",
    "        for context in prompt_dict:\n",
    "            for attribute in prompt_dict[context].keys():\n",
    "                prompt, label = prompt_dict[context][attribute]\n",
    "\n",
    "                domain_dataset.append(\n",
    "                    {\n",
    "                        \"entity\": entity_name,\n",
    "                        \"context\": context,\n",
    "                        \"attribute\": attribute,\n",
    "                        \"prompt\": prompt,\n",
    "                        \"label\": label,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    if save_dir is not None:\n",
    "        temp = Dataset.from_list(domain_dataset)\n",
    "        temp.save_to_disk(os.path.join(save_dir, f\"{qid}_{len(all_entities)}\"))\n",
    "\n",
    "    return Dataset.from_list(domain_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity 0-th entity\n",
      "Skipping entity 1-th entity\n",
      "Skipping entity 2-th entity\n",
      "Skipping entity 3-th entity\n",
      "Skipping entity 4-th entity\n",
      "Skipping entity 5-th entity\n",
      "Skipping entity 6-th entity\n",
      "Skipping entity 7-th entity\n",
      "Skipping entity 8-th entity\n",
      "Skipping entity 9-th entity\n",
      "Skipping entity 10-th entity\n",
      "Skipping entity 11-th entity\n",
      "Skipping entity 12-th entity\n",
      "Skipping entity 13-th entity\n",
      "Skipping entity 14-th entity\n",
      "Skipping entity 15-th entity\n",
      "Skipping entity 16-th entity\n",
      "Skipping entity 17-th entity\n",
      "Skipping entity 18-th entity\n",
      "Skipping entity 19-th entity\n",
      "Skipping entity 20-th entity\n",
      "Skipping entity 21-th entity\n",
      "Skipping entity 22-th entity\n",
      "Skipping entity 23-th entity\n",
      "Skipping entity 24-th entity\n",
      "Skipping entity 25-th entity\n",
      "Skipping entity 26-th entity\n",
      "Skipping entity 27-th entity\n",
      "Skipping entity 28-th entity\n",
      "Skipping entity 29-th entity\n",
      "Skipping entity 30-th entity\n",
      "Skipping entity 31-th entity\n",
      "Skipping entity 32-th entity\n",
      "Skipping entity 33-th entity\n",
      "Skipping entity 34-th entity\n",
      "Skipping entity 35-th entity\n",
      "Skipping entity 36-th entity\n",
      "Skipping entity 37-th entity\n",
      "Skipping entity 38-th entity\n",
      "Skipping entity 39-th entity\n",
      "Skipping entity 40-th entity\n",
      "Skipping entity 41-th entity\n",
      "Skipping entity 42-th entity\n",
      "Skipping entity 43-th entity\n",
      "Skipping entity 44-th entity\n",
      "Skipping entity 45-th entity\n",
      "Skipping entity 46-th entity\n",
      "Skipping entity 47-th entity\n",
      "Skipping entity 48-th entity\n",
      "Skipping entity 49-th entity\n",
      "Skipping entity 50-th entity\n",
      "Skipping entity 51-th entity\n",
      "Skipping entity 52-th entity\n",
      "Skipping entity 53-th entity\n",
      "Skipping entity 54-th entity\n",
      "Skipping entity 55-th entity\n",
      "Skipping entity 56-th entity\n",
      "Skipping entity 57-th entity\n",
      "Skipping entity 58-th entity\n",
      "Skipping entity 59-th entity\n",
      "Skipping entity 60-th entity\n",
      "Skipping entity 61-th entity\n",
      "Skipping entity 62-th entity\n",
      "Skipping entity 63-th entity\n",
      "Skipping entity 64-th entity\n",
      "Skipping entity 65-th entity\n",
      "Skipping entity 66-th entity\n",
      "Skipping entity 67-th entity\n",
      "Skipping entity 68-th entity\n",
      "Skipping entity 69-th entity\n",
      "Skipping entity 70-th entity\n",
      "Skipping entity 71-th entity\n",
      "Skipping entity 72-th entity\n",
      "Skipping entity 73-th entity\n",
      "Skipping entity 74-th entity\n",
      "Skipping entity 75-th entity\n",
      "Skipping entity 76-th entity\n",
      "Skipping entity 77-th entity\n",
      "Skipping entity 78-th entity\n",
      "Skipping entity 79-th entity\n",
      "Skipping entity 80-th entity\n",
      "Skipping entity 81-th entity\n",
      "Skipping entity 82-th entity\n",
      "Skipping entity 83-th entity\n",
      "Skipping entity 84-th entity\n",
      "Skipping entity 85-th entity\n",
      "Skipping entity 86-th entity\n",
      "Skipping entity 87-th entity\n",
      "Skipping entity 88-th entity\n",
      "Skipping entity 89-th entity\n",
      "Skipping entity 90-th entity\n",
      "Skipping entity 91-th entity\n",
      "Skipping entity 92-th entity\n",
      "Skipping entity 93-th entity\n",
      "Skipping entity 94-th entity\n",
      "Skipping entity 95-th entity\n",
      "Skipping entity 96-th entity\n",
      "Skipping entity 97-th entity\n",
      "Skipping entity 98-th entity\n",
      "Skipping entity 99-th entity\n",
      "Skipping entity 100-th entity\n",
      "Skipping entity 101-th entity\n",
      "Skipping entity 102-th entity\n",
      "Skipping entity 103-th entity\n",
      "Skipping entity 104-th entity\n",
      "Skipping entity 105-th entity\n",
      "Skipping entity 106-th entity\n",
      "Skipping entity 107-th entity\n",
      "Skipping entity 108-th entity\n",
      "Skipping entity 109-th entity\n",
      "Skipping entity 110-th entity\n",
      "Skipping entity 111-th entity\n",
      "Skipping entity 112-th entity\n",
      "Skipping entity 113-th entity\n",
      "Skipping entity 114-th entity\n",
      "Skipping entity 115-th entity\n",
      "Skipping entity 116-th entity\n",
      "Skipping entity 117-th entity\n",
      "Skipping entity 118-th entity\n",
      "Skipping entity 119-th entity\n",
      "Skipping entity 120-th entity\n",
      "Skipping entity 121-th entity\n",
      "Skipping entity 122-th entity\n",
      "Skipping entity 123-th entity\n",
      "Skipping entity 124-th entity\n",
      "Skipping entity 125-th entity\n",
      "Skipping entity 126-th entity\n",
      "Skipping entity 127-th entity\n",
      "Skipping entity 128-th entity\n",
      "Skipping entity 129-th entity\n",
      "Skipping entity 130-th entity\n",
      "Skipping entity 131-th entity\n",
      "Skipping entity 132-th entity\n",
      "Skipping entity 133-th entity\n",
      "Skipping entity 134-th entity\n",
      "Skipping entity 135-th entity\n",
      "Skipping entity 136-th entity\n",
      "Skipping entity 137-th entity\n",
      "Skipping entity 138-th entity\n",
      "Skipping entity 139-th entity\n",
      "Skipping entity 140-th entity\n",
      "Skipping entity 141-th entity\n",
      "Skipping entity 142-th entity\n",
      "Skipping entity 143-th entity\n",
      "Skipping entity 144-th entity\n",
      "Skipping entity 145-th entity\n",
      "Skipping entity 146-th entity\n",
      "Skipping entity 147-th entity\n",
      "Skipping entity 148-th entity\n",
      "Skipping entity 149-th entity\n",
      "Skipping entity 150-th entity\n",
      "Skipping entity 151-th entity\n",
      "Skipping entity 152-th entity\n",
      "Skipping entity 153-th entity\n",
      "Skipping entity 154-th entity\n",
      "Skipping entity 155-th entity\n",
      "Skipping entity 156-th entity\n",
      "Skipping entity 157-th entity\n",
      "Skipping entity 158-th entity\n",
      "Skipping entity 159-th entity\n",
      "Skipping entity 160-th entity\n",
      "Skipping entity 161-th entity\n",
      "Skipping entity 162-th entity\n",
      "Skipping entity 163-th entity\n",
      "Skipping entity 164-th entity\n",
      "Skipping entity 165-th entity\n",
      "Skipping entity 166-th entity\n",
      "Skipping entity 167-th entity\n",
      "Skipping entity 168-th entity\n",
      "Skipping entity 169-th entity\n",
      "Skipping entity 170-th entity\n",
      "Skipping entity 171-th entity\n",
      "Skipping entity 172-th entity\n",
      "Skipping entity 173-th entity\n",
      "Skipping entity 174-th entity\n",
      "Skipping entity 175-th entity\n",
      "Skipping entity 176-th entity\n",
      "Skipping entity 177-th entity\n",
      "Skipping entity 178-th entity\n",
      "Skipping entity 179-th entity\n",
      "Skipping entity 180-th entity\n",
      "Skipping entity 181-th entity\n",
      "Skipping entity 182-th entity\n",
      "Skipping entity 183-th entity\n",
      "Skipping entity 184-th entity\n",
      "Skipping entity 185-th entity\n",
      "Skipping entity 186-th entity\n",
      "Skipping entity 187-th entity\n",
      "Skipping entity 188-th entity\n",
      "Skipping entity 189-th entity\n",
      "Skipping entity 190-th entity\n",
      "Skipping entity 191-th entity\n",
      "Skipping entity 192-th entity\n",
      "Skipping entity 193-th entity\n",
      "Skipping entity 194-th entity\n",
      "Skipping entity 195-th entity\n",
      "Skipping entity 196-th entity\n",
      "Skipping entity 197-th entity\n",
      "Skipping entity 198-th entity\n",
      "Skipping entity 199-th entity\n",
      "Skipping entity 200-th entity\n",
      "Skipping entity 201-th entity\n",
      "Skipping entity 202-th entity\n",
      "Skipping entity 203-th entity\n",
      "Skipping entity 204-th entity\n",
      "Skipping entity 205-th entity\n",
      "Skipping entity 206-th entity\n",
      "Skipping entity 207-th entity\n",
      "Skipping entity 208-th entity\n",
      "Skipping entity 209-th entity\n",
      "Skipping entity 210-th entity\n",
      "Skipping entity 211-th entity\n",
      "Skipping entity 212-th entity\n",
      "Skipping entity 213-th entity\n",
      "Skipping entity 214-th entity\n",
      "Skipping entity 215-th entity\n",
      "Skipping entity 216-th entity\n",
      "Skipping entity 217-th entity\n",
      "Skipping entity 218-th entity\n",
      "Skipping entity 219-th entity\n",
      "Skipping entity 220-th entity\n",
      "Skipping entity 221-th entity\n",
      "Skipping entity 222-th entity\n",
      "Skipping entity 223-th entity\n",
      "Skipping entity 224-th entity\n",
      "Skipping entity 225-th entity\n",
      "Skipping entity 226-th entity\n",
      "Skipping entity 227-th entity\n",
      "Skipping entity 228-th entity\n",
      "Skipping entity 229-th entity\n",
      "Skipping entity 230-th entity\n",
      "Skipping entity 231-th entity\n",
      "Skipping entity 232-th entity\n",
      "Skipping entity 233-th entity\n",
      "Skipping entity 234-th entity\n",
      "Skipping entity 235-th entity\n",
      "Skipping entity 236-th entity\n",
      "Skipping entity 237-th entity\n",
      "Skipping entity 238-th entity\n",
      "Skipping entity 239-th entity\n",
      "Skipping entity 240-th entity\n",
      "Skipping entity 241-th entity\n",
      "Skipping entity 242-th entity\n",
      "Skipping entity 243-th entity\n",
      "Skipping entity 244-th entity\n",
      "Skipping entity 245-th entity\n",
      "Skipping entity 246-th entity\n",
      "Skipping entity 247-th entity\n",
      "Skipping entity 248-th entity\n",
      "Skipping entity 249-th entity\n",
      "Skipping entity 250-th entity\n",
      "Skipping entity 251-th entity\n",
      "Skipping entity 252-th entity\n",
      "Skipping entity 253-th entity\n",
      "Skipping entity 254-th entity\n",
      "Skipping entity 255-th entity\n",
      "Skipping entity 256-th entity\n",
      "Skipping entity 257-th entity\n",
      "Skipping entity 258-th entity\n",
      "Skipping entity 259-th entity\n",
      "Skipping entity 260-th entity\n",
      "Skipping entity 261-th entity\n",
      "Skipping entity 262-th entity\n",
      "Skipping entity 263-th entity\n",
      "Skipping entity 264-th entity\n",
      "Skipping entity 265-th entity\n",
      "Skipping entity 266-th entity\n",
      "Skipping entity 267-th entity\n",
      "Skipping entity 268-th entity\n",
      "Skipping entity 269-th entity\n",
      "Skipping entity 270-th entity\n",
      "Skipping entity 271-th entity\n",
      "Skipping entity 272-th entity\n",
      "Skipping entity 273-th entity\n",
      "Skipping entity 274-th entity\n",
      "Skipping entity 275-th entity\n",
      "Skipping entity 276-th entity\n",
      "Skipping entity 277-th entity\n",
      "Skipping entity 278-th entity\n",
      "Skipping entity 279-th entity\n",
      "Skipping entity 280-th entity\n",
      "Skipping entity 281-th entity\n",
      "Skipping entity 282-th entity\n",
      "Skipping entity 283-th entity\n",
      "Skipping entity 284-th entity\n",
      "Skipping entity 285-th entity\n",
      "Skipping entity 286-th entity\n",
      "Skipping entity 287-th entity\n",
      "Skipping entity 288-th entity\n",
      "Skipping entity 289-th entity\n",
      "Skipping entity 290-th entity\n",
      "Skipping entity 291-th entity\n",
      "Skipping entity 292-th entity\n",
      "Skipping entity 293-th entity\n",
      "Skipping entity 294-th entity\n",
      "Skipping entity 295-th entity\n",
      "Skipping entity 296-th entity\n",
      "Skipping entity 297-th entity\n",
      "Skipping entity 298-th entity\n",
      "Skipping entity 299-th entity\n",
      "Skipping entity 300-th entity\n",
      "Skipping entity 301-th entity\n",
      "Skipping entity 302-th entity\n",
      "Skipping entity 303-th entity\n",
      "Skipping entity 304-th entity\n",
      "Skipping entity 305-th entity\n",
      "Skipping entity 306-th entity\n",
      "Skipping entity 307-th entity\n",
      "Skipping entity 308-th entity\n",
      "Skipping entity 309-th entity\n",
      "Skipping entity 310-th entity\n",
      "Skipping entity 311-th entity\n",
      "Skipping entity 312-th entity\n",
      "Skipping entity 313-th entity\n",
      "Skipping entity 314-th entity\n",
      "Skipping entity 315-th entity\n",
      "Skipping entity 316-th entity\n",
      "Skipping entity 317-th entity\n",
      "Skipping entity 318-th entity\n",
      "Skipping entity 319-th entity\n",
      "Skipping entity 320-th entity\n",
      "Skipping entity 321-th entity\n",
      "Skipping entity 322-th entity\n",
      "Skipping entity 323-th entity\n",
      "Skipping entity 324-th entity\n",
      "Skipping entity 325-th entity\n",
      "Skipping entity 326-th entity\n",
      "Skipping entity 327-th entity\n",
      "Skipping entity 328-th entity\n",
      "Skipping entity 329-th entity\n",
      "Skipping entity 330-th entity\n",
      "Skipping entity 331-th entity\n",
      "Skipping entity 332-th entity\n",
      "Skipping entity 333-th entity\n",
      "Skipping entity 334-th entity\n",
      "Skipping entity 335-th entity\n",
      "Skipping entity 336-th entity\n",
      "Skipping entity 337-th entity\n",
      "Skipping entity 338-th entity\n",
      "Skipping entity 339-th entity\n",
      "Skipping entity 340-th entity\n",
      "Skipping entity 341-th entity\n",
      "Skipping entity 342-th entity\n",
      "Skipping entity 343-th entity\n",
      "Skipping entity 344-th entity\n",
      "Skipping entity 345-th entity\n",
      "Skipping entity 346-th entity\n",
      "Skipping entity 347-th entity\n",
      "Skipping entity 348-th entity\n",
      "Skipping entity 349-th entity\n",
      "Skipping entity 350-th entity\n",
      "Skipping entity 351-th entity\n",
      "Skipping entity 352-th entity\n",
      "Skipping entity 353-th entity\n",
      "Skipping entity 354-th entity\n",
      "Skipping entity 355-th entity\n",
      "Skipping entity 356-th entity\n",
      "Skipping entity 357-th entity\n",
      "Skipping entity 358-th entity\n",
      "Skipping entity 359-th entity\n",
      "Skipping entity 360-th entity\n",
      "Skipping entity 361-th entity\n",
      "Skipping entity 362-th entity\n",
      "Skipping entity 363-th entity\n",
      "Skipping entity 364-th entity\n",
      "Skipping entity 365-th entity\n",
      "Skipping entity 366-th entity\n",
      "Skipping entity 367-th entity\n",
      "Skipping entity 368-th entity\n",
      "Skipping entity 369-th entity\n",
      "Skipping entity 370-th entity\n",
      "Skipping entity 371-th entity\n",
      "Skipping entity 372-th entity\n",
      "Skipping entity 373-th entity\n",
      "Skipping entity 374-th entity\n",
      "Skipping entity 375-th entity\n",
      "Skipping entity 376-th entity\n",
      "Skipping entity 377-th entity\n",
      "Skipping entity 378-th entity\n",
      "Skipping entity 379-th entity\n",
      "Skipping entity 380-th entity\n",
      "Skipping entity 381-th entity\n",
      "Skipping entity 382-th entity\n",
      "Skipping entity 383-th entity\n",
      "Skipping entity 384-th entity\n",
      "Skipping entity 385-th entity\n",
      "Skipping entity 386-th entity\n",
      "Skipping entity 387-th entity\n",
      "Skipping entity 388-th entity\n",
      "Skipping entity 389-th entity\n",
      "Skipping entity 390-th entity\n",
      "Skipping entity 391-th entity\n",
      "Skipping entity 392-th entity\n",
      "Skipping entity 393-th entity\n",
      "Skipping entity 394-th entity\n",
      "Skipping entity 395-th entity\n",
      "Skipping entity 396-th entity\n",
      "Skipping entity 397-th entity\n",
      "Skipping entity 398-th entity\n",
      "Skipping entity 399-th entity\n",
      "Skipping entity 400-th entity\n",
      "Skipping entity 401-th entity\n",
      "Skipping entity 402-th entity\n",
      "Skipping entity 403-th entity\n",
      "Skipping entity 404-th entity\n",
      "Skipping entity 405-th entity\n",
      "Skipping entity 406-th entity\n",
      "Skipping entity 407-th entity\n",
      "Skipping entity 408-th entity\n",
      "Skipping entity 409-th entity\n",
      "Skipping entity 410-th entity\n",
      "Skipping entity 411-th entity\n",
      "Skipping entity 412-th entity\n",
      "Skipping entity 413-th entity\n",
      "Skipping entity 414-th entity\n",
      "Skipping entity 415-th entity\n",
      "Skipping entity 416-th entity\n",
      "Skipping entity 417-th entity\n",
      "Skipping entity 418-th entity\n",
      "Skipping entity 419-th entity\n",
      "Skipping entity 420-th entity\n",
      "Skipping entity 421-th entity\n",
      "Skipping entity 422-th entity\n",
      "Skipping entity 423-th entity\n",
      "Skipping entity 424-th entity\n",
      "Skipping entity 425-th entity\n",
      "Skipping entity 426-th entity\n",
      "Skipping entity 427-th entity\n",
      "Skipping entity 428-th entity\n",
      "Skipping entity 429-th entity\n",
      "Skipping entity 430-th entity\n",
      "Skipping entity 431-th entity\n",
      "Skipping entity 432-th entity\n",
      "Skipping entity 433-th entity\n",
      "Skipping entity 434-th entity\n",
      "Skipping entity 435-th entity\n",
      "Skipping entity 436-th entity\n",
      "Skipping entity 437-th entity\n",
      "Skipping entity 438-th entity\n",
      "Skipping entity 439-th entity\n",
      "Skipping entity 440-th entity\n",
      "Skipping entity 441-th entity\n",
      "Skipping entity 442-th entity\n",
      "Skipping entity 443-th entity\n",
      "Skipping entity 444-th entity\n",
      "Skipping entity 445-th entity\n",
      "Skipping entity 446-th entity\n",
      "Skipping entity 447-th entity\n",
      "Skipping entity 448-th entity\n",
      "Skipping entity 449-th entity\n",
      "Skipping entity 450-th entity\n",
      "Skipping entity 451-th entity\n",
      "Skipping entity 452-th entity\n",
      "Skipping entity 453-th entity\n",
      "Skipping entity 454-th entity\n",
      "Skipping entity 455-th entity\n",
      "Skipping entity 456-th entity\n",
      "Skipping entity 457-th entity\n",
      "Skipping entity 458-th entity\n",
      "Skipping entity 459-th entity\n",
      "Skipping entity 460-th entity\n",
      "Skipping entity 461-th entity\n",
      "Skipping entity 462-th entity\n",
      "Skipping entity 463-th entity\n",
      "Skipping entity 464-th entity\n",
      "Skipping entity 465-th entity\n",
      "Skipping entity 466-th entity\n",
      "Skipping entity 467-th entity\n",
      "Skipping entity 468-th entity\n",
      "Skipping entity 469-th entity\n",
      "Skipping entity 470-th entity\n",
      "Skipping entity 471-th entity\n",
      "Skipping entity 472-th entity\n",
      "Skipping entity 473-th entity\n",
      "Skipping entity 474-th entity\n",
      "Skipping entity 475-th entity\n",
      "Skipping entity 476-th entity\n",
      "Skipping entity 477-th entity\n",
      "Skipping entity 478-th entity\n",
      "Skipping entity 479-th entity\n",
      "Skipping entity 480-th entity\n",
      "Skipping entity 481-th entity\n",
      "Skipping entity 482-th entity\n",
      "Skipping entity 483-th entity\n",
      "Skipping entity 484-th entity\n",
      "Skipping entity 485-th entity\n",
      "Skipping entity 486-th entity\n",
      "Skipping entity 487-th entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/user/24141/ipykernel_2801920/2697326428.py:76: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  selected_keys = random.sample(filtered_attributes.keys(), n_property)\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4020/4020 [00:00<00:00, 341698.29 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4055/4055 [00:00<00:00, 272982.52 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4100/4100 [00:00<00:00, 225402.68 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4140/4140 [00:00<00:00, 260926.81 examples/s]\n",
      " 26%|██▌       | 520/2000 [07:01<19:59,  1.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid URL\n",
      "\n",
      "No Wikipedia article found for this language.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "InvalidURL",
     "evalue": "Invalid URL 'https:///w/api.php': No host supplied",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidURL\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m generate_domain_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ5\u001b[39m\u001b[38;5;124m\"\u001b[39m, num_of_context\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_property\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, save_per_entity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./auto_ravel\u001b[39m\u001b[38;5;124m\"\u001b[39m, resuming_from\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./auto_ravel/Q5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 53\u001b[0m, in \u001b[0;36mgenerate_domain_dataset\u001b[0;34m(qid, num_of_context, n_property, limit, save_per_entity, save_dir, resuming_from)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 53\u001b[0m     wikipedia_content \u001b[38;5;241m=\u001b[39m \u001b[43mget_wikipedia_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwikipedia_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mget_wikipedia_content\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Making the request\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidURL:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid URL\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/nlp/scr/sjd24/miniconda3/envs/hypernet/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nlp/scr/sjd24/miniconda3/envs/hypernet/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/nlp/scr/sjd24/miniconda3/envs/hypernet/lib/python3.10/site-packages/requests/sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[1;32m    564\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[1;32m    565\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    579\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    580\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    581\u001b[0m )\n",
      "File \u001b[0;32m/nlp/scr/sjd24/miniconda3/envs/hypernet/lib/python3.10/site-packages/requests/sessions.py:484\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    481\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    483\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 484\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCaseInsensitiveDict\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m/nlp/scr/sjd24/miniconda3/envs/hypernet/lib/python3.10/site-packages/requests/models.py:367\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_method(method)\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[0;32m/nlp/scr/sjd24/miniconda3/envs/hypernet/lib/python3.10/site-packages/requests/models.py:444\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No scheme supplied. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerhaps you meant https://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m     )\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[0;32m--> 444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: No host supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# In general, we want to try IDNA encoding the hostname if the string contains\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# non-ASCII characters. This allows users to automatically get the correct IDNA\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# behaviour. For strings containing only ASCII characters, we need to also verify\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# it doesn't start with a wildcard (*), before allowing the unencoded hostname.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unicode_is_ascii(host):\n",
      "\u001b[0;31mInvalidURL\u001b[0m: Invalid URL 'https:///w/api.php': No host supplied"
     ]
    }
   ],
   "source": [
    "dataset = await generate_domain_dataset(\n",
    "    \"Q5\",\n",
    "    num_of_context=1,\n",
    "    n_property=5,\n",
    "    limit=2000,\n",
    "    save_per_entity=10,\n",
    "    save_dir=\"./auto_ravel\",\n",
    "    resuming_from=\"./auto_ravel/Q5\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:01<00:00,  2.82it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "import torch\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    \"/nlp/scr/sjd24/llama3-8b\", torch_dtype=torch.bfloat16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/nlp/scr/sjd24/llama3-8b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_prediction_labels(model, tokenizer, target_dataset, max_num_tokens=3):\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        input_texts = []\n",
    "\n",
    "        for b in batch:\n",
    "            prefix = b[\"context\"]\n",
    "            suffix = b[\"prompt\"]\n",
    "\n",
    "            input_text = f\"{tokenizer.bos_token} {prefix}{suffix}\"\n",
    "            input_texts.append(input_text)\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            input_texts, return_tensors=\"pt\", padding=True, truncation=True\n",
    "        )\n",
    "        # inputs[\"position_ids\"] = torch.cumsum(inputs[\"attention_mask\"], dim=1) * inputs[\"attention_mask\"] - 1\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    model_predictions = []\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        target_dataset, batch_size=16, collate_fn=collate_fn, shuffle=False\n",
    "    )\n",
    "\n",
    "    model = model.to(\"cuda\")\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "        outputs = model.generate(**batch, max_new_tokens=max_num_tokens)\n",
    "\n",
    "        outputs = outputs[:, batch[\"input_ids\"].shape[1] :]\n",
    "\n",
    "        predictions = [\n",
    "            tokenizer.decode(output, skip_special_tokens=True) for output in outputs\n",
    "        ]\n",
    "        model_predictions.extend(predictions)\n",
    "\n",
    "    target_dataset = target_dataset.add_column(\"model_predictions\", model_predictions)\n",
    "\n",
    "    return target_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypernet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

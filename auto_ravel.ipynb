{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get All Domains in Wikidata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from json import JSONDecodeError\n",
    "from time import sleep\n",
    "import re\n",
    "from urllib.parse import unquote, urlparse\n",
    "import openai\n",
    "\n",
    "url = 'https://query.wikidata.org/sparql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain_entites(qid):\n",
    "    \n",
    "    query = f'''\n",
    "        SELECT ?entity ?entityLabel\n",
    "        WHERE {{\n",
    "            ?entity wdt:P31 wd:{qid}.\n",
    "            ?entity rdfs:label ?entityLabel filter (lang(?entityLabel) = \"en\")\n",
    "        }}\n",
    "        LIMIT 10000\n",
    "    '''\n",
    "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "    try:\n",
    "        data = r.json()\n",
    "    except JSONDecodeError:\n",
    "        sleep(5)\n",
    "        r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "        data = r.json()\n",
    "    \n",
    "    entities = dict()\n",
    "    \n",
    "    for e in data['results']['bindings']:\n",
    "        entity_id = e[\"entity\"]['value'].split('/')[-1]\n",
    "        entity_label = e[\"entityLabel\"]['value']\n",
    "        entities[entity_id] = entity_label\n",
    "        \n",
    "    return entities\n",
    "\n",
    "\n",
    "def get_entity_attributes(qid):\n",
    "    \n",
    "    query = f'''\n",
    "        SELECT ?property ?propertyLabel ?value ?valueLabel\n",
    "        WHERE {{\n",
    "            wd:{qid} ?p ?value .\n",
    "            ?property wikibase:directClaim ?p .\n",
    "            SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "        }}\n",
    "    '''\n",
    "    r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "    try:\n",
    "        data = r.json()\n",
    "    except JSONDecodeError:\n",
    "        sleep(5)\n",
    "        r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "        data = r.json()\n",
    "    \n",
    "    properties = dict()\n",
    "    \n",
    "    for p in data['results']['bindings']:\n",
    "        property_id = p[\"property\"]['value'].split('/')[-1]\n",
    "        property_label = p[\"propertyLabel\"]['value']\n",
    "        value_label = p[\"valueLabel\"]['value']\n",
    "        \n",
    "        if property_id.startswith('P'):\n",
    "            properties[property_id] = (property_label, value_label)\n",
    "                \n",
    "    return properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_content(url):\n",
    "    # Extracting the title from the URL\n",
    "    parsed_url = urlparse(url)\n",
    "    title = unquote(parsed_url.path.split('/')[-1])\n",
    "    \n",
    "    # API request setup\n",
    "    api_url = f'https://{parsed_url.netloc}/w/api.php'\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'titles': title,\n",
    "        'prop': 'extracts',\n",
    "        'explaintext': True,\n",
    "    }\n",
    "\n",
    "    # Making the request\n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extracting the page content\n",
    "    page = next(iter(data['query']['pages'].values()))\n",
    "    if 'extract' in page:\n",
    "        return page['extract']\n",
    "    else:\n",
    "        return 'Article content not found.'\n",
    "    \n",
    "def get_wikipedia_sentences(content, entity_name, word_upper_limit=20, word_lower_limit=5):\n",
    "    # Splitting the content into sentences by \". \", \".\\n\" or \".\\t\"\n",
    "    sentences = [s.strip() for s in re.split(r'\\.|\\;|\\,|\\n|\\!|\\?', content)]\n",
    "    \n",
    "    # Filtering the sentences that mention the entity\n",
    "    entity_sentences = [s for s in sentences if entity_name in s]\n",
    "    \n",
    "    # Filtering the sentences by word count\n",
    "    entity_sentences = [s for s in entity_sentences if len(s.split()) <= word_upper_limit and len(s.split()) >= word_lower_limit]\n",
    "    \n",
    "    return entity_sentences\n",
    "\n",
    "def get_wikipedia_url(wikidata_id, language='en'):\n",
    "    # Constructing the URL to call the API\n",
    "    url = f'https://www.wikidata.org/w/api.php'\n",
    "    params = {\n",
    "        'action': 'wbgetentities',\n",
    "        'ids': wikidata_id,\n",
    "        'format': 'json',\n",
    "        'props': 'sitelinks'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Accessing the sitelink for the specified language\n",
    "    try:\n",
    "        wikipedia_title = data['entities'][wikidata_id]['sitelinks'][f'{language}wiki']['title']\n",
    "        wikipedia_url = f\"https://{language}.wikipedia.org/wiki/{wikipedia_title.replace(' ', '_')}\"\n",
    "        return wikipedia_url\n",
    "    except KeyError:\n",
    "        return \"No Wikipedia article found for this language.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "def filter_attribute(attribute):\n",
    "    \n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "        api_key = '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'\n",
    "    )\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Classify the following attribute into 'common knowledge' or 'specialized'.\\nExamples of common knowledge attribute: Cause of death, Nationality, Country of origin\\nExamples of specialized attribute: Canadiana Name Authority ID, Diamond Catalog ID for persons and organisations\\n\\n\\n\" + \"Attribute\" + attribute + \"\\n\\nClass: \"\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "    # OpenAI API Key setup\n",
    "    content = chat_completion.choices[0].message.content\n",
    "    return content\n",
    "\n",
    "def filter_attributes (attributes):\n",
    "    filtered_attributes = dict()\n",
    "    for attribute in attributes:\n",
    "        filtered_attributes[attribute] = filter_attribute(attributes[attribute][0])\n",
    "    return filtered_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get Domain Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = get_domain_entites('Q11424')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = get_entity_attributes(\"Q91\")\n",
    "filtered_attributes = filter_attributes(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head': {'vars': ['article']}, 'results': {'bindings': []}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qqq = \"\"\"\n",
    "    SELECT ?article\n",
    "    WHERE {\n",
    "    wd:Q91 schema:about ?article .\n",
    "    ?article schema:isPartOf <https://en.wikipedia.org/> .\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "r = requests.get(url, params = {'format': 'json', 'query': qqq})\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikipedia_content(url):\n",
    "    # Extracting the title from the URL\n",
    "    parsed_url = urlparse(url)\n",
    "    title = unquote(parsed_url.path.split('/')[-1])\n",
    "    \n",
    "    # API request setup\n",
    "    api_url = f'https://{parsed_url.netloc}/w/api.php'\n",
    "    params = {\n",
    "        'action': 'query',\n",
    "        'format': 'json',\n",
    "        'titles': title,\n",
    "        'prop': 'extracts',\n",
    "        'explaintext': True,\n",
    "    }\n",
    "\n",
    "    # Making the request\n",
    "    response = requests.get(api_url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extracting the page content\n",
    "    page = next(iter(data['query']['pages'].values()))\n",
    "    if 'extract' in page:\n",
    "        return page['extract']\n",
    "    else:\n",
    "        return 'Article content not found.'\n",
    "    \n",
    "def get_wikipedia_sentences(content, entity_name, word_upper_limit=20, word_lower_limit=5):\n",
    "    # Splitting the content into sentences by \". \", \".\\n\" or \".\\t\"\n",
    "    sentences = [s.strip() for s in re.split(r'\\.|\\;|\\,|\\n|\\!|\\?', content)]\n",
    "    \n",
    "    # Filtering the sentences that mention the entity\n",
    "    entity_sentences = [s for s in sentences if entity_name in s]\n",
    "    \n",
    "    # Filtering the sentences by word count\n",
    "    entity_sentences = [s for s in entity_sentences if len(s.split()) <= word_upper_limit and len(s.split()) >= word_lower_limit]\n",
    "    \n",
    "    return entity_sentences\n",
    "\n",
    "def get_wikipedia_url(wikidata_id, language='en'):\n",
    "    # Constructing the URL to call the API\n",
    "    url = f'https://www.wikidata.org/w/api.php'\n",
    "    params = {\n",
    "        'action': 'wbgetentities',\n",
    "        'ids': wikidata_id,\n",
    "        'format': 'json',\n",
    "        'props': 'sitelinks'\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Accessing the sitelink for the specified language\n",
    "    try:\n",
    "        wikipedia_title = data['entities'][wikidata_id]['sitelinks'][f'{language}wiki']['title']\n",
    "        wikipedia_url = f\"https://{language}.wikipedia.org/wiki/{wikipedia_title.replace(' ', '_')}\"\n",
    "        return wikipedia_url\n",
    "    except KeyError:\n",
    "        return \"No Wikipedia article found for this language.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "wikidata_id = 'Q91'  # Abraham Lincoln\n",
    "uri = get_wikipedia_url(wikidata_id)\n",
    "content = get_wikipedia_content(uri)\n",
    "sentences = get_wikipedia_sentences(content, 'Abraham Lincoln')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Abraham Lincoln ( LINK-ən', 'Abraham Lincoln was born on February 12', 'Captain Abraham Lincoln and wife Bathsheba (née Herring) moved the family from Virginia to Jefferson County', 'Abraham Lincoln', 'Zann Gill describes how these two murders set off a chain reaction that ultimately prompted Abraham Lincoln to run for President', 'Schwartz argues that in the 1930s and 1940s the memory of Abraham Lincoln was practically sacred and provided the nation with \"a moral symbol inspiring and guiding American life', 'The United States Navy Nimitz-class aircraft carrier USS Abraham Lincoln (CVN-72) is named after Lincoln', 'include the Abraham Lincoln Presidential Library and Museum', 'Congress officially dedicated room H-226 in the United States Capitol to Abraham Lincoln', 'The room is located off National Statuary Hall and served as the post office of the House while then-Representative Abraham Lincoln served in Congress from 1847 to 1849', 'Outline of Abraham Lincoln', 'Abraham Lincoln Presidential Library and Museum', \"The Lincoln Presidential Library's ongoing digitization of all documents written by or to Abraham Lincoln during his lifetime\", 'Collected Works of Abraham Lincoln – complete collected works as edited by Basler et al', 'Abraham Lincoln Association Archived April 28', 'Abraham Lincoln Bicentennial Foundation', 'Abraham Lincoln collected news and commentary at The New York Times', '\"Abraham Lincoln (id: L000313)\"', 'Abraham Lincoln: A Resource Guide from the Library of Congress', '\"Life Portrait of Abraham Lincoln\"', '\"Writings of Abraham Lincoln\" from C-SPAN\\'s American Writers: A Journey Through History', 'Abraham Lincoln: Original Letters and Manuscripts – Shapell Manuscript Foundation', 'Lincoln/Net: Abraham Lincoln Historical Digitization Project – Northern Illinois University Libraries', 'Teaching Abraham Lincoln Archived December 10', 'Works by Abraham Lincoln at Project Gutenberg', 'Works by or about Abraham Lincoln at the Internet Archive', 'Works by Abraham Lincoln at LibriVox (public domain audiobooks)', 'Abraham Lincoln Recollections and Newspaper Articles Collection Archived November 13']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P268 Bibliothèque nationale de France ID 11888092r\n"
     ]
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "    SELECT ?property ?propertyLabel ?value ?valueLabel\n",
    "    WHERE {\n",
    "        wd:Q42 ?p ?value .\n",
    "        ?property wikibase:directClaim ?p .\n",
    "        SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "r = requests.get(url, params = {'format': 'json', 'query': q})\n",
    "\n",
    "for p in r.json()['results']['bindings']:\n",
    "    property_id = p[\"property\"]['value'].split('/')[-1]\n",
    "    property_label = p[\"propertyLabel\"]['value']\n",
    "    value_label = p[\"valueLabel\"]['value']\n",
    "    print(property_id, property_label, value_label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = dict()\n",
    "\n",
    "for class_id in domains.keys():\n",
    "    query = f'''\n",
    "        SELECT ?entity\n",
    "        WHERE {{\n",
    "        ?entity wdt:P31 wd:Q6542625.\n",
    "        ?entity rdfs:label ?entityLabel filter (lang(?entityLabel) = \"en\")\n",
    "        }}\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "    SELECT ?subclass ?classLabel \n",
    "    WHERE {{\n",
    "        ?subclass wdt:P279 wd:Q6542625.  \n",
    "        ?subclass rdfs:label ?classLabel filter (lang(?classLabel) = \"en\")\n",
    "    }}\n",
    "'''\n",
    "r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head': {'vars': ['subclass', 'classLabel']}, 'results': {'bindings': []}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "    SELECT ?subclass  \n",
    "    WHERE {{\n",
    "        ?subclass wdt:P31 wd:Q16889133.  \n",
    "        ?subclass rdfs:label ?classLabel filter (lang(?classLabel) = \"en\")\n",
    "    }}\n",
    "'''\n",
    "r = requests.get(url, params = {'format': 'json', 'query': query})\n",
    "r.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypernet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "\n",
    "from src.hyperdas.data_utils import (\n",
    "    filter_dataset,\n",
    "    generate_ravel_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d",
      "i",
      "c",
      "t",
      "_",
      "k",
      "e",
      "y",
      "s",
      "(",
      "[",
      "'",
      "F",
      "i",
      "e",
      "l",
      "d",
      "'",
      ",",
      " ",
      "'",
      "A",
      "w",
      "a",
      "r",
      "d",
      " ",
      "Y",
      "e",
      "a",
      "r",
      "'",
      ",",
      " ",
      "'",
      "B",
      "i",
      "r",
      "t",
      "h",
      " ",
      "Y",
      "e",
      "a",
      "r",
      "'",
      ",",
      " ",
      "'",
      "C",
      "o",
      "u",
      "n",
      "t",
      "r",
      "y",
      " ",
      "o",
      "f",
      " ",
      "B",
      "i",
      "r",
      "t",
      "h",
      "'",
      ",",
      " ",
      "'",
      "G",
      "e",
      "n",
      "d",
      "e",
      "r",
      "'",
      "]",
      ")",
      "\n"
     ]
    }
   ],
   "source": [
    "p = \"/workspace/HyperDAS/assets/data/ravel/ravel_nobel_prize_winner_attribute_to_prompts.json\"\n",
    "with open(p, \"r\") as f:\n",
    "    prompts = json.load(f)\n",
    "    print(prompts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"meta-llama/Meta-Llama-3-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/",
      "u",
      "s",
      "r",
      "/",
      "l",
      "o",
      "c",
      "a",
      "l",
      "/",
      "l",
      "i",
      "b",
      "/",
      "p",
      "y",
      "t",
      "h",
      "o",
      "n",
      "3",
      ".",
      "1",
      "0",
      "/",
      "d",
      "i",
      "s",
      "t",
      "-",
      "p",
      "a",
      "c",
      "k",
      "a",
      "g",
      "e",
      "s",
      "/",
      "h",
      "u",
      "g",
      "g",
      "i",
      "n",
      "g",
      "f",
      "a",
      "c",
      "e",
      "_",
      "h",
      "u",
      "b",
      "/",
      "f",
      "i",
      "l",
      "e",
      "_",
      "d",
      "o",
      "w",
      "n",
      "l",
      "o",
      "a",
      "d",
      ".",
      "p",
      "y",
      ":",
      "7",
      "9",
      "7",
      ":",
      " ",
      "F",
      "u",
      "t",
      "u",
      "r",
      "e",
      "W",
      "a",
      "r",
      "n",
      "i",
      "n",
      "g",
      ":",
      " ",
      "`",
      "r",
      "e",
      "s",
      "u",
      "m",
      "e",
      "_",
      "d",
      "o",
      "w",
      "n",
      "l",
      "o",
      "a",
      "d",
      "`",
      " ",
      "i",
      "s",
      " ",
      "d",
      "e",
      "p",
      "r",
      "e",
      "c",
      "a",
      "t",
      "e",
      "d",
      " ",
      "a",
      "n",
      "d",
      " ",
      "w",
      "i",
      "l",
      "l",
      " ",
      "b",
      "e",
      " ",
      "r",
      "e",
      "m",
      "o",
      "v",
      "e",
      "d",
      " ",
      "i",
      "n",
      " ",
      "v",
      "e",
      "r",
      "s",
      "i",
      "o",
      "n",
      " ",
      "1",
      ".",
      "0",
      ".",
      "0",
      ".",
      " ",
      "D",
      "o",
      "w",
      "n",
      "l",
      "o",
      "a",
      "d",
      "s",
      " ",
      "a",
      "l",
      "w",
      "a",
      "y",
      "s",
      " ",
      "r",
      "e",
      "s",
      "u",
      "m",
      "e",
      " ",
      "w",
      "h",
      "e",
      "n",
      " ",
      "p",
      "o",
      "s",
      "s",
      "i",
      "b",
      "l",
      "e",
      ".",
      " ",
      "I",
      "f",
      " ",
      "y",
      "o",
      "u",
      " ",
      "w",
      "a",
      "n",
      "t",
      " ",
      "t",
      "o",
      " ",
      "f",
      "o",
      "r",
      "c",
      "e",
      " ",
      "a",
      " ",
      "n",
      "e",
      "w",
      " ",
      "d",
      "o",
      "w",
      "n",
      "l",
      "o",
      "a",
      "d",
      ",",
      " ",
      "u",
      "s",
      "e",
      " ",
      "`",
      "f",
      "o",
      "r",
      "c",
      "e",
      "_",
      "d",
      "o",
      "w",
      "n",
      "l",
      "o",
      "a",
      "d",
      "=",
      "T",
      "r",
      "u",
      "e",
      "`",
      ".",
      "\n",
      " ",
      " ",
      "w",
      "a",
      "r",
      "n",
      "i",
      "n",
      "g",
      "s",
      ".",
      "w",
      "a",
      "r",
      "n",
      "(",
      "\n",
      "S",
      "p",
      "e",
      "c",
      "i",
      "a",
      "l",
      " ",
      "t",
      "o",
      "k",
      "e",
      "n",
      "s",
      " ",
      "h",
      "a",
      "v",
      "e",
      " ",
      "b",
      "e",
      "e",
      "n",
      " ",
      "a",
      "d",
      "d",
      "e",
      "d",
      " ",
      "i",
      "n",
      " ",
      "t",
      "h",
      "e",
      " ",
      "v",
      "o",
      "c",
      "a",
      "b",
      "u",
      "l",
      "a",
      "r",
      "y",
      ",",
      " ",
      "m",
      "a",
      "k",
      "e",
      " ",
      "s",
      "u",
      "r",
      "e",
      " ",
      "t",
      "h",
      "e",
      " ",
      "a",
      "s",
      "s",
      "o",
      "c",
      "i",
      "a",
      "t",
      "e",
      "d",
      " ",
      "w",
      "o",
      "r",
      "d",
      " ",
      "e",
      "m",
      "b",
      "e",
      "d",
      "d",
      "i",
      "n",
      "g",
      "s",
      " ",
      "a",
      "r",
      "e",
      " ",
      "f",
      "i",
      "n",
      "e",
      "-",
      "t",
      "u",
      "n",
      "e",
      "d",
      " ",
      "o",
      "r",
      " ",
      "t",
      "r",
      "a",
      "i",
      "n",
      "e",
      "d",
      ".",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed9f964417342e398f8fbd45434727a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = LlamaForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16)\n",
    "model = model.cuda()\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 39\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Create hash based on dataset generation args\u001b[39;00m\n\u001b[1;32m     29\u001b[0m args_hash \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhash\u001b[39m(\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mfrozenset\u001b[39m(\n\u001b[1;32m     31\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m )\n\u001b[0;32m---> 39\u001b[0m dataset \u001b[38;5;241m=\u001b[39m filter_dataset(\u001b[43mmodel\u001b[49m, tokenizer, dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m     40\u001b[0m dataset \u001b[38;5;241m=\u001b[39m filter_dataset(model, tokenizer, dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m     41\u001b[0m dataset \u001b[38;5;241m=\u001b[39m filter_dataset(model, tokenizer, dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# CHANGE: {base_entity} â†’ {source_entity} | ATTR: {target_attribute}\n",
    "from collections import defaultdict\n",
    "\n",
    "all_attributes = {\n",
    "    \"city\": [\"Country\", \"Continent\", \"Language\", \"Latitude\", \"Longitude\", \"Timezone\"],\n",
    "    \"nobel_prize_winner\": [\n",
    "        \"Field\",\n",
    "        \"Award Year\",\n",
    "        \"Birth Year\",\n",
    "        \"Country of Birth\",\n",
    "        \"Gender\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "target_attributes = {\n",
    "    \"city\": [\"Country\", \"Continent\"],\n",
    "    \"nobel_prize_winner\": [\"Field\", \"Country of Birth\"],\n",
    "}\n",
    "\n",
    "\n",
    "domains = [\"city\", \"nobel_prize_winner\"]\n",
    "all_datasets = defaultdict(list)\n",
    "\n",
    "for domain in domains:\n",
    "    for split in [\"train\", \"test\"]:\n",
    "        args = {\n",
    "            \"n_samples\": 10000,\n",
    "            \"root_path\": \"/workspace/HyperDAS/assets/data/ravel\",\n",
    "            \"target_attributes\": target_attributes[domain],\n",
    "            \"isolate_attributes\": list(\n",
    "                set(all_attributes[domain]) - set(target_attributes[domain])\n",
    "            ),\n",
    "            \"template_split\": split,\n",
    "            \"entity_split\": split,\n",
    "            \"domain\": domain,\n",
    "            # \"edit_instruction_template\": \"CHANGE: {base_entity} -> {source_entity} | ATTR: {random_target_attribute}\",\n",
    "        }\n",
    "\n",
    "        dataset = generate_ravel_dataset(**args)\n",
    "\n",
    "        dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "        dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "        dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "\n",
    "        metadata = {\n",
    "            **args,\n",
    "            \"target_attributes\": tuple(args[\"target_attributes\"]),\n",
    "            \"isolate_attributes\": tuple(args[\"isolate_attributes\"]),\n",
    "        }\n",
    "\n",
    "        all_datasets[split].append((dataset, metadata))\n",
    "\n",
    "for split, dataset_list in datasets.items():\n",
    "    metadata_list, dataset_list = zip(*dataset_list)\n",
    "    combined = datasets.concatenate_datasets(dataset_list)\n",
    "    path = f\"/workspace/HyperDAS/experiments/RAVEL/data/multi_entity_{split}\"\n",
    "    combined.save_to_disk(path)\n",
    "    with open(os.path.join(path, \"metadata.json\"), \"w\") as f:\n",
    "        json.dump({\"metadata\": metadata_list}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypernet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

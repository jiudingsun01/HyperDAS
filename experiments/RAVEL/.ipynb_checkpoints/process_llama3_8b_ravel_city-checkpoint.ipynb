{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "\n",
    "from src.hyperdas.data_utils import (\n",
    "    filter_dataset,\n",
    "    generate_ravel_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = \"meta-llama/Meta-Llama-3-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/",
      "u",
      "s",
      "r",
      "/",
      "l",
      "o",
      "c",
      "a",
      "l",
      "/",
      "l",
      "i",
      "b",
      "/",
      "p",
      "y",
      "t",
      "h",
      "o",
      "n",
      "3",
      ".",
      "1",
      "0",
      "/",
      "d",
      "i",
      "s",
      "t",
      "-",
      "p",
      "a",
      "c",
      "k",
      "a",
      "g",
      "e",
      "s",
      "/",
      "h",
      "u",
      "g",
      "g",
      "i",
      "n",
      "g",
      "f",
      "a",
      "c",
      "e",
      "_",
      "h",
      "u",
      "b",
      "/",
      "f",
      "i",
      "l",
      "e",
      "_",
      "d",
      "o",
      "w",
      "n",
      "l",
      "o",
      "a",
      "d",
      ".",
      "p",
      "y",
      ":",
      "7",
      "9",
      "7",
      ":",
      " ",
      "F",
      "u",
      "t",
      "u",
      "r",
      "e",
      "W",
      "a",
      "r",
      "n",
      "i",
      "n",
      "g",
      ":",
      " ",
      "`",
      "r",
      "e",
      "s",
      "u",
      "m",
      "e",
      "_",
      "d",
      "o",
      "w",
      "n",
      "l",
      "o",
      "a",
      "d",
      "`",
      " ",
      "i",
      "s",
      " ",
      "d",
      "e",
      "p",
      "r",
      "e",
      "c",
      "a",
      "t",
      "e",
      "d",
      " ",
      "a",
      "n",
      "d",
      " ",
      "w",
      "i",
      "l",
      "l",
      " ",
      "b",
      "e",
      " ",
      "r",
      "e",
      "m",
      "o",
      "v",
      "e",
      "d",
      " ",
      "i",
      "n",
      " ",
      "v",
      "e",
      "r",
      "s",
      "i",
      "o",
      "n",
      " ",
      "1",
      ".",
      "0",
      ".",
      "0",
      ".",
      " ",
      "D",
      "o",
      "w",
      "n",
      "l",
      "o",
      "a",
      "d",
      "s",
      " ",
      "a",
      "l",
      "w",
      "a",
      "y",
      "s",
      " ",
      "r",
      "e",
      "s",
      "u",
      "m",
      "e",
      " ",
      "w",
      "h",
      "e",
      "n",
      " ",
      "p",
      "o",
      "s",
      "s",
      "i",
      "b",
      "l",
      "e",
      ".",
      " ",
      "I",
      "f",
      " ",
      "y",
      "o",
      "u",
      " ",
      "w",
      "a",
      "n",
      "t",
      " ",
      "t",
      "o",
      " ",
      "f",
      "o",
      "r",
      "c",
      "e",
      " ",
      "a",
      " ",
      "n",
      "e",
      "w",
      " ",
      "d",
      "o",
      "w",
      "n",
      "l",
      "o",
      "a",
      "d",
      ",",
      " ",
      "u",
      "s",
      "e",
      " ",
      "`",
      "f",
      "o",
      "r",
      "c",
      "e",
      "_",
      "d",
      "o",
      "w",
      "n",
      "l",
      "o",
      "a",
      "d",
      "=",
      "T",
      "r",
      "u",
      "e",
      "`",
      ".",
      "\n",
      " ",
      " ",
      "w",
      "a",
      "r",
      "n",
      "i",
      "n",
      "g",
      "s",
      ".",
      "w",
      "a",
      "r",
      "n",
      "(",
      "\n",
      "S",
      "p",
      "e",
      "c",
      "i",
      "a",
      "l",
      " ",
      "t",
      "o",
      "k",
      "e",
      "n",
      "s",
      " ",
      "h",
      "a",
      "v",
      "e",
      " ",
      "b",
      "e",
      "e",
      "n",
      " ",
      "a",
      "d",
      "d",
      "e",
      "d",
      " ",
      "i",
      "n",
      " ",
      "t",
      "h",
      "e",
      " ",
      "v",
      "o",
      "c",
      "a",
      "b",
      "u",
      "l",
      "a",
      "r",
      "y",
      ",",
      " ",
      "m",
      "a",
      "k",
      "e",
      " ",
      "s",
      "u",
      "r",
      "e",
      " ",
      "t",
      "h",
      "e",
      " ",
      "a",
      "s",
      "s",
      "o",
      "c",
      "i",
      "a",
      "t",
      "e",
      "d",
      " ",
      "w",
      "o",
      "r",
      "d",
      " ",
      "e",
      "m",
      "b",
      "e",
      "d",
      "d",
      "i",
      "n",
      "g",
      "s",
      " ",
      "a",
      "r",
      "e",
      " ",
      "f",
      "i",
      "n",
      "e",
      "-",
      "t",
      "u",
      "n",
      "e",
      "d",
      " ",
      "o",
      "r",
      " ",
      "t",
      "r",
      "a",
      "i",
      "n",
      "e",
      "d",
      ".",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3dcc8ee40284fd5b22e9c3f34d14f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "model = LlamaForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16)\n",
    "model = model.cuda()\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6",
      "2",
      "5",
      "i",
      "t",
      " ",
      "[",
      "0",
      "0",
      ":",
      "5",
      "0",
      ",",
      " ",
      "1",
      "2",
      ".",
      "3",
      "0",
      "i",
      "t",
      "/",
      "s",
      "]",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A",
      "c",
      "c",
      "u",
      "r",
      "a",
      "c",
      "y",
      ":",
      " ",
      "0",
      ".",
      "5",
      "8",
      "8",
      "3",
      ";",
      " ",
      "f",
      "i",
      "l",
      "t",
      "e",
      "r",
      "e",
      "d",
      " ",
      "o",
      "u",
      "t",
      " ",
      "4",
      "1",
      "1",
      "7",
      " ",
      "e",
      "x",
      "a",
      "m",
      "p",
      "l",
      "e",
      "s",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3",
      "6",
      "8",
      "i",
      "t",
      " ",
      "[",
      "0",
      "0",
      ":",
      "2",
      "7",
      ",",
      " ",
      "1",
      "3",
      ".",
      "2",
      "0",
      "i",
      "t",
      "/",
      "s",
      "]",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A",
      "c",
      "c",
      "u",
      "r",
      "a",
      "c",
      "y",
      ":",
      " ",
      "0",
      ".",
      "9",
      "9",
      "5",
      "9",
      "2",
      "0",
      "4",
      "4",
      "8",
      "7",
      "5",
      "0",
      "6",
      "3",
      "7",
      "5",
      ";",
      " ",
      "f",
      "i",
      "l",
      "t",
      "e",
      "r",
      "e",
      "d",
      " ",
      "o",
      "u",
      "t",
      " ",
      "2",
      "4",
      " ",
      "e",
      "x",
      "a",
      "m",
      "p",
      "l",
      "e",
      "s",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3",
      "6",
      "7",
      "i",
      "t",
      " ",
      "[",
      "0",
      "0",
      ":",
      "2",
      "5",
      ",",
      " ",
      "1",
      "4",
      ".",
      "5",
      "8",
      "i",
      "t",
      "/",
      "s",
      "]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A",
      "c",
      "c",
      "u",
      "r",
      "a",
      "c",
      "y",
      ":",
      " ",
      "0",
      ".",
      "9",
      "9",
      "8",
      "9",
      "7",
      "5",
      "9",
      "3",
      "4",
      "4",
      "5",
      "9",
      "8",
      "0",
      "5",
      "5",
      ";",
      " ",
      "f",
      "i",
      "l",
      "t",
      "e",
      "r",
      "e",
      "d",
      " ",
      "o",
      "u",
      "t",
      " ",
      "6",
      " ",
      "e",
      "x",
      "a",
      "m",
      "p",
      "l",
      "e",
      "s",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7bb8059c5c47dab573a3de3128c4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5853 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6",
      "2",
      "5",
      "i",
      "t",
      " ",
      "[",
      "0",
      "0",
      ":",
      "4",
      "5",
      ",",
      " ",
      "1",
      "3",
      ".",
      "8",
      "4",
      "i",
      "t",
      "/",
      "s",
      "]",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A",
      "c",
      "c",
      "u",
      "r",
      "a",
      "c",
      "y",
      ":",
      " ",
      "0",
      ".",
      "5",
      "8",
      "0",
      "4",
      ";",
      " ",
      "f",
      "i",
      "l",
      "t",
      "e",
      "r",
      "e",
      "d",
      " ",
      "o",
      "u",
      "t",
      " ",
      "4",
      "1",
      "9",
      "6",
      " ",
      "e",
      "x",
      "a",
      "m",
      "p",
      "l",
      "e",
      "s",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3",
      "6",
      "3",
      "i",
      "t",
      " ",
      "[",
      "0",
      "0",
      ":",
      "2",
      "5",
      ",",
      " ",
      "1",
      "4",
      ".",
      "4",
      "5",
      "i",
      "t",
      "/",
      "s",
      "]",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A",
      "c",
      "c",
      "u",
      "r",
      "a",
      "c",
      "y",
      ":",
      " ",
      "0",
      ".",
      "9",
      "9",
      "4",
      "3",
      "1",
      "4",
      "2",
      "6",
      "6",
      "0",
      "2",
      "3",
      "4",
      "3",
      "2",
      "1",
      ";",
      " ",
      "f",
      "i",
      "l",
      "t",
      "e",
      "r",
      "e",
      "d",
      " ",
      "o",
      "u",
      "t",
      " ",
      "3",
      "3",
      " ",
      "e",
      "x",
      "a",
      "m",
      "p",
      "l",
      "e",
      "s",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3",
      "6",
      "1",
      "i",
      "t",
      " ",
      "[",
      "0",
      "0",
      ":",
      "2",
      "4",
      ",",
      " ",
      "1",
      "4",
      ".",
      "6",
      "6",
      "i",
      "t",
      "/",
      "s",
      "]",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A",
      "c",
      "c",
      "u",
      "r",
      "a",
      "c",
      "y",
      ":",
      " ",
      "0",
      ".",
      "9",
      "9",
      "7",
      "5",
      "7",
      "4",
      "0",
      "7",
      "7",
      "2",
      "8",
      "2",
      "9",
      "6",
      "6",
      "5",
      ";",
      " ",
      "f",
      "i",
      "l",
      "t",
      "e",
      "r",
      "e",
      "d",
      " ",
      "o",
      "u",
      "t",
      " ",
      "1",
      "4",
      " ",
      "e",
      "x",
      "a",
      "m",
      "p",
      "l",
      "e",
      "s",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dab647f430a4c9389c672bb679873c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5757 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_attributes = [\n",
    "    \"Country\",\n",
    "    \"Continent\",\n",
    "    \"Language\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Timezone\",\n",
    "]\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "    dataset = generate_ravel_dataset(\n",
    "        10000,\n",
    "        root_path=\"/workspace/HyperDAS/assets/data/ravel\",\n",
    "        target_attributes=[\"Country\", \"Continent\"],\n",
    "        isolate_attributes=list(set(all_attributes) - set([\"Country\", \"Continent\"])),\n",
    "        template_split=split,\n",
    "        entity_split=split,\n",
    "    )\n",
    "\n",
    "    dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "    dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "    dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "\n",
    "    dataset.save_to_disk(\n",
    "        f\"/workspace/HyperDAS/experiments/RAVEL/data/city_country_{split}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6",
      "2",
      "5",
      "i",
      "t",
      " ",
      "[",
      "0",
      "0",
      ":",
      "4",
      "9",
      ",",
      " ",
      "1",
      "2",
      ".",
      "5",
      "9",
      "i",
      "t",
      "/",
      "s",
      "]",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A",
      "c",
      "c",
      "u",
      "r",
      "a",
      "c",
      "y",
      ":",
      " ",
      "0",
      ".",
      "5",
      "9",
      "5",
      "6",
      ";",
      " ",
      "f",
      "i",
      "l",
      "t",
      "e",
      "r",
      "e",
      "d",
      " ",
      "o",
      "u",
      "t",
      " ",
      "4",
      "0",
      "4",
      "4",
      " ",
      "e",
      "x",
      "a",
      "m",
      "p",
      "l",
      "e",
      "s",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3",
      "7",
      "3",
      "i",
      "t",
      " ",
      "[",
      "0",
      "0",
      ":",
      "2",
      "7",
      ",",
      " ",
      "1",
      "3",
      ".",
      "7",
      "5",
      "i",
      "t",
      "/",
      "s",
      "]",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A",
      "c",
      "c",
      "u",
      "r",
      "a",
      "c",
      "y",
      ":",
      " ",
      "0",
      ".",
      "9",
      "9",
      "7",
      "1",
      "4",
      "5",
      "7",
      "3",
      "5",
      "3",
      "9",
      "2",
      "8",
      "8",
      "1",
      "1",
      ";",
      " ",
      "f",
      "i",
      "l",
      "t",
      "e",
      "r",
      "e",
      "d",
      " ",
      "o",
      "u",
      "t",
      " ",
      "1",
      "7",
      " ",
      "e",
      "x",
      "a",
      "m",
      "p",
      "l",
      "e",
      "s",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3",
      "7",
      "2",
      "i",
      "t",
      " ",
      "[",
      "0",
      "0",
      ":",
      "2",
      "5",
      ",",
      " ",
      "1",
      "4",
      ".",
      "6",
      "4",
      "i",
      "t",
      "/",
      "s",
      "]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A",
      "c",
      "c",
      "u",
      "r",
      "a",
      "c",
      "y",
      ":",
      " ",
      "0",
      ".",
      "9",
      "9",
      "8",
      "8",
      "2",
      "1",
      "3",
      "5",
      "0",
      "3",
      "9",
      "5",
      "6",
      "8",
      "9",
      "5",
      ";",
      " ",
      "f",
      "i",
      "l",
      "t",
      "e",
      "r",
      "e",
      "d",
      " ",
      "o",
      "u",
      "t",
      " ",
      "7",
      " ",
      "e",
      "x",
      "a",
      "m",
      "p",
      "l",
      "e",
      "s",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651a65af480449e2ae0600de9244ce8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5932 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6",
      "2",
      "5",
      "i",
      "t",
      " ",
      "[",
      "0",
      "0",
      ":",
      "4",
      "4",
      ",",
      " ",
      "1",
      "3",
      ".",
      "9",
      "7",
      "i",
      "t",
      "/",
      "s",
      "]",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A",
      "c",
      "c",
      "u",
      "r",
      "a",
      "c",
      "y",
      ":",
      " ",
      "0",
      ".",
      "5",
      "8",
      "8",
      "4",
      ";",
      " ",
      "f",
      "i",
      "l",
      "t",
      "e",
      "r",
      "e",
      "d",
      " ",
      "o",
      "u",
      "t",
      " ",
      "4",
      "1",
      "1",
      "6",
      " ",
      "e",
      "x",
      "a",
      "m",
      "p",
      "l",
      "e",
      "s",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3",
      "6",
      "8",
      "i",
      "t",
      " ",
      "[",
      "0",
      "0",
      ":",
      "2",
      "5",
      ",",
      " ",
      "1",
      "4",
      ".",
      "3",
      "1",
      "i",
      "t",
      "/",
      "s",
      "]",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A",
      "c",
      "c",
      "u",
      "r",
      "a",
      "c",
      "y",
      ":",
      " ",
      "0",
      ".",
      "9",
      "9",
      "5",
      "4",
      "1",
      "1",
      "2",
      "8",
      "4",
      "8",
      "4",
      "0",
      "2",
      "4",
      "4",
      "8",
      ";",
      " ",
      "f",
      "i",
      "l",
      "t",
      "e",
      "r",
      "e",
      "d",
      " ",
      "o",
      "u",
      "t",
      " ",
      "2",
      "7",
      " ",
      "e",
      "x",
      "a",
      "m",
      "p",
      "l",
      "e",
      "s",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3",
      "6",
      "7",
      "i",
      "t",
      " ",
      "[",
      "0",
      "0",
      ":",
      "2",
      "4",
      ",",
      " ",
      "1",
      "4",
      ".",
      "7",
      "6",
      "i",
      "t",
      "/",
      "s",
      "]",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A",
      "c",
      "c",
      "u",
      "r",
      "a",
      "c",
      "y",
      ":",
      " ",
      "0",
      ".",
      "9",
      "9",
      "9",
      "4",
      "8",
      "7",
      "7",
      "9",
      "2",
      "3",
      "8",
      "5",
      "1",
      "8",
      "0",
      "2",
      ";",
      " ",
      "f",
      "i",
      "l",
      "t",
      "e",
      "r",
      "e",
      "d",
      " ",
      "o",
      "u",
      "t",
      " ",
      "3",
      " ",
      "e",
      "x",
      "a",
      "m",
      "p",
      "l",
      "e",
      "s",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a44dbe01a21248fe83c9086453c6590b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5854 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CHANGE: {base_entity} → {source_entity} | ATTR: {target_attribute}\n",
    "all_attributes = [\n",
    "    \"Country\",\n",
    "    \"Continent\",\n",
    "    \"Language\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Timezone\",\n",
    "]\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "    dataset = generate_ravel_dataset(\n",
    "        10000,\n",
    "        root_path=\"/workspace/HyperDAS/assets/data/ravel\",\n",
    "        target_attributes=[\"Country\", \"Continent\"],\n",
    "        isolate_attributes=list(set(all_attributes) - set([\"Country\", \"Continent\"])),\n",
    "        template_split=split,\n",
    "        entity_split=split,\n",
    "        edit_instruction_template=\"CHANGE: {base_entity} -> {source_entity} | ATTR: {random_target_attribute}\",\n",
    "    )\n",
    "\n",
    "    dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "    dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "    dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "\n",
    "    dataset.save_to_disk(\n",
    "        f\"/workspace/HyperDAS/experiments/RAVEL/data/city_country_{split}_v0.1\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attributes = [\n",
    "    \"Country\",\n",
    "    \"Continent\",\n",
    "    \"Language\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Timezone\",\n",
    "]\n",
    "\n",
    "for attribute in all_attributes:\n",
    "    for split, size in [(\"train\", 20000), (\"test\", 4000)]:\n",
    "        print(f\"Generating data for {attribute} in split {split}\")\n",
    "        all_other_attributes = [a for a in all_attributes if a != attribute]\n",
    "\n",
    "        dataset = generate_ravel_dataset(\n",
    "            size,\n",
    "            root_path=\"/home/ubuntu/HyperDAS/data/ravel\",\n",
    "            target_attributes=[attribute],\n",
    "            isolate_attributes=all_other_attributes,\n",
    "            template_split=split,\n",
    "            entity_split=\"both\",\n",
    "        )\n",
    "\n",
    "        dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "        dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "        dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "\n",
    "        dataset.save_to_disk(\n",
    "            f\"/home/ubuntu/HyperDAS/experiments/ravel/data/city_{attribute.lower()}_{split}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ravel_causal_dataset(split):\n",
    "    dataset = generate_ravel_dataset(\n",
    "        10000,\n",
    "        root_path=\"/workspace/HyperDAS/assets/data/ravel\",\n",
    "        target_attributes=[\"Country\"],\n",
    "        isolate_attributes=[],\n",
    "        template_split=split,\n",
    "        entity_split=split,\n",
    "    )\n",
    "\n",
    "    dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "    dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "    dataset = filter_dataset(model, tokenizer, dataset, batch_size=16)\n",
    "\n",
    "    dataset.save_to_disk(\n",
    "        f\"/workspace/HyperDAS/experiments/RAVEL/data/ravel_country_causal_only_{split}\"\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = (\n",
    "    generate_ravel_causal_dataset(\"train\"),\n",
    "    generate_ravel_causal_dataset(\"test\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_country = [d for d in test_dataset if d[\"attribute\"] == \"Country\"]\n",
    "all_country_with_isolation = [\n",
    "    d\n",
    "    for d in test_dataset\n",
    "    if d[\"attribute\"] == \"Country\" and d[\"attribute_type\"] == \"isolate\"\n",
    "]\n",
    "len(test_dataset), len(all_country), len(all_country_with_isolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_dict = {}\n",
    "\n",
    "for d in test_dataset:\n",
    "    if d[\"attribute\"] not in attr_dict:\n",
    "        attr_dict[d[\"attribute\"]] = 0\n",
    "\n",
    "    attr_dict[d[\"attribute\"]] += 1\n",
    "\n",
    "attr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hypernet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

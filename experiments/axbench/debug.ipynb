{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load parquet file into pandas dataframe\n",
    "df_latent_inf = pd.read_parquet(\n",
    "    \"/Users/sidbaskaran/Desktop/research/HyperDAS/axbench/axbench/concept10/prod_2b_l10_v1/inference/latent_eval_data.parquet\"\n",
    ")\n",
    "df_generate_train_data = pd.read_parquet(\n",
    "    \"/Users/sidbaskaran/Desktop/research/HyperDAS/axbench/axbench/concept10/prod_2b_l10_v1/generate/train_data.parquet\"\n",
    ")\n",
    "\n",
    "# Load pickle file containing inference state\n",
    "with open(\n",
    "    \"/Users/sidbaskaran/Desktop/research/HyperDAS/axbench/axbench/concept10/prod_2b_l10_v1/inference/latent_inference_state.pkl\",\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    inference_state = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb98ab22b6d405a9bcffb1d00ffa2af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390ef6c281bc445ca4604c9a4346a237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data.parquet:   0%|          | 0.00/10.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5c4aad9f8140838f195f17b8d03051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data.parquet:   0%|          | 0.00/10.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fe68f9652743538604c079b8aa5c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data.parquet:   0%|          | 0.00/10.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3858b851709b40bdbd733f79fbe60f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data.parquet:   0%|          | 0.00/10.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5533504f997647009776adfdb4393575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data.parquet:   0%|          | 0.00/10.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9aae6ee5b44108b3060c98b78c2c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data.parquet:   0%|          | 0.00/10.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf41919081e14ff8ba97268397a0f8c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data.parquet:   0%|          | 0.00/9.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5587772bf0349599fe327973cd092ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data.parquet:   0%|          | 0.00/9.93M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b2ba0e70414a0497a7bd2bbebbe655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/144864 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e666943233b475cb17dbe24072d72b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/152116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read file '/root/.cache/huggingface/hub/datasets--pyvene--axbench-concept500/snapshots/ad8a5d60c4616b599c24dd6689f05f696ec610f3/2b/l10/test/data.parquet' with error <class 'datasets.table.CastError'>: Couldn't cast\n",
      "input: string\n",
      "output: string\n",
      "output_concept: string\n",
      "concept_genre: string\n",
      "category: string\n",
      "dataset_category: string\n",
      "concept_id: int64\n",
      "sae_link: string\n",
      "sae_id: int64\n",
      "-- schema metadata --\n",
      "pandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 1141\n",
      "to\n",
      "{'input': Value(dtype='string', id=None), 'output': Value(dtype='string', id=None), 'output_concept': Value(dtype='string', id=None), 'concept_genre': Value(dtype='string', id=None), 'category': Value(dtype='string', id=None), 'dataset_category': Value(dtype='string', id=None), 'concept_id': Value(dtype='int64', id=None)}\n",
      "because column names don't match\n"
     ]
    },
    {
     "ename": "DatasetGenerationError",
     "evalue": "An error occurred while generating the dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCastError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/builder.py:1854\u001b[39m, in \u001b[36mArrowBasedBuilder._prepare_split_single\u001b[39m\u001b[34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[39m\n\u001b[32m   1853\u001b[39m _time = time.time()\n\u001b[32m-> \u001b[39m\u001b[32m1854\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1855\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_shard_size\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/packaged_modules/parquet/parquet.py:106\u001b[39m, in \u001b[36mParquet._generate_tables\u001b[39m\u001b[34m(self, files)\u001b[39m\n\u001b[32m    103\u001b[39m         \u001b[38;5;66;03m# Uncomment for debugging (will print the Arrow table size and elements)\u001b[39;00m\n\u001b[32m    104\u001b[39m         \u001b[38;5;66;03m# logger.warning(f\"pa_table: {pa_table} num rows: {pa_table.num_rows}\")\u001b[39;00m\n\u001b[32m    105\u001b[39m         \u001b[38;5;66;03m# logger.warning('\\n'.join(str(pa_table.slice(i, 1).to_pydict()) for i in range(pa_table.num_rows)))\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cast_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/packaged_modules/parquet/parquet.py:73\u001b[39m, in \u001b[36mParquet._cast_table\u001b[39m\u001b[34m(self, pa_table)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info.features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# more expensive cast to support nested features with keys in a different order\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# allows str <-> int/float or str to Audio for example\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     pa_table = \u001b[43mtable_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43marrow_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m pa_table\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/table.py:2292\u001b[39m, in \u001b[36mtable_cast\u001b[39m\u001b[34m(table, schema)\u001b[39m\n\u001b[32m   2291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m table.schema != schema:\n\u001b[32m-> \u001b[39m\u001b[32m2292\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast_table_to_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2293\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m table.schema.metadata != schema.metadata:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/table.py:2240\u001b[39m, in \u001b[36mcast_table_to_schema\u001b[39m\u001b[34m(table, schema)\u001b[39m\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m table_column_names <= \u001b[38;5;28mset\u001b[39m(schema.names):\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CastError(\n\u001b[32m   2241\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt cast\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(table.schema)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mto\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_short_str(features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mbecause column names don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt match\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2242\u001b[39m         table_column_names=table.column_names,\n\u001b[32m   2243\u001b[39m         requested_column_names=\u001b[38;5;28mlist\u001b[39m(features),\n\u001b[32m   2244\u001b[39m     )\n\u001b[32m   2245\u001b[39m arrays = [\n\u001b[32m   2246\u001b[39m     cast_array_to_feature(\n\u001b[32m   2247\u001b[39m         table[name] \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m table_column_names \u001b[38;5;28;01melse\u001b[39;00m pa.array([\u001b[38;5;28;01mNone\u001b[39;00m] * \u001b[38;5;28mlen\u001b[39m(table), \u001b[38;5;28mtype\u001b[39m=schema.field(name).type),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2250\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name, feature \u001b[38;5;129;01min\u001b[39;00m features.items()\n\u001b[32m   2251\u001b[39m ]\n",
      "\u001b[31mCastError\u001b[39m: Couldn't cast\ninput: string\noutput: string\noutput_concept: string\nconcept_genre: string\ncategory: string\ndataset_category: string\nconcept_id: int64\nsae_link: string\nsae_id: int64\n-- schema metadata --\npandas: '{\"index_columns\": [], \"column_indexes\": [], \"columns\": [{\"name\":' + 1141\nto\n{'input': Value(dtype='string', id=None), 'output': Value(dtype='string', id=None), 'output_concept': Value(dtype='string', id=None), 'concept_genre': Value(dtype='string', id=None), 'category': Value(dtype='string', id=None), 'dataset_category': Value(dtype='string', id=None), 'concept_id': Value(dtype='int64', id=None)}\nbecause column names don't match",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDatasetGenerationError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m ds = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyvene/axbench-concept500\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/load.py:2151\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[39m\n\u001b[32m   2148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m builder_instance.as_streaming_dataset(split=split)\n\u001b[32m   2150\u001b[39m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2151\u001b[39m \u001b[43mbuilder_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2157\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2159\u001b[39m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[32m   2160\u001b[39m keep_in_memory = (\n\u001b[32m   2161\u001b[39m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance.info.dataset_size)\n\u001b[32m   2162\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/builder.py:924\u001b[39m, in \u001b[36mDatasetBuilder.download_and_prepare\u001b[39m\u001b[34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    923\u001b[39m     prepare_split_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_proc\u001b[39m\u001b[33m\"\u001b[39m] = num_proc\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[32m    931\u001b[39m \u001b[38;5;28mself\u001b[39m.info.dataset_size = \u001b[38;5;28msum\u001b[39m(split.num_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.info.splits.values())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/builder.py:1000\u001b[39m, in \u001b[36mDatasetBuilder._download_and_prepare\u001b[39m\u001b[34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[39m\n\u001b[32m    996\u001b[39m split_dict.add(split_generator.split_info)\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    999\u001b[39m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1000\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1002\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[32m   1003\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot find data file. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1004\u001b[39m         + (\u001b[38;5;28mself\u001b[39m.manual_download_instructions \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1005\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1006\u001b[39m         + \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[32m   1007\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/builder.py:1741\u001b[39m, in \u001b[36mArrowBasedBuilder._prepare_split\u001b[39m\u001b[34m(self, split_generator, file_format, num_proc, max_shard_size)\u001b[39m\n\u001b[32m   1739\u001b[39m job_id = \u001b[32m0\u001b[39m\n\u001b[32m   1740\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pbar:\n\u001b[32m-> \u001b[39m\u001b[32m1741\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prepare_split_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjob_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_prepare_split_args\u001b[49m\n\u001b[32m   1743\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/dist-packages/datasets/builder.py:1897\u001b[39m, in \u001b[36mArrowBasedBuilder._prepare_split_single\u001b[39m\u001b[34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, DatasetGenerationError):\n\u001b[32m   1896\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1897\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetGenerationError(\u001b[33m\"\u001b[39m\u001b[33mAn error occurred while generating the dataset\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01myield\u001b[39;00m job_id, \u001b[38;5;28;01mTrue\u001b[39;00m, (total_num_examples, total_num_bytes, writer._features, num_shards, shard_lengths)\n",
      "\u001b[31mDatasetGenerationError\u001b[39m: An error occurred while generating the dataset"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"pyvene/axbench-concept500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c43b6dacf34e098ca54cd4967a2010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma2ForCausalLM(\n",
      "  (model): Gemma2Model(\n",
      "    (embed_tokens): Embedding(256000, 2304, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-25): 26 x Gemma2DecoderLayer(\n",
      "        (self_attn): Gemma2Attention(\n",
      "          (q_proj): Linear(in_features=2304, out_features=2048, bias=False)\n",
      "          (k_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
      "          (v_proj): Linear(in_features=2304, out_features=1024, bias=False)\n",
      "          (o_proj): Linear(in_features=2048, out_features=2304, bias=False)\n",
      "          (rotary_emb): Gemma2RotaryEmbedding()\n",
      "        )\n",
      "        (mlp): Gemma2MLP(\n",
      "          (gate_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
      "          (up_proj): Linear(in_features=2304, out_features=9216, bias=False)\n",
      "          (down_proj): Linear(in_features=9216, out_features=2304, bias=False)\n",
      "          (act_fn): PytorchGELUTanh()\n",
      "        )\n",
      "        (input_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "        (pre_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "        (post_feedforward_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "        (post_attention_layernorm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "      )\n",
      "    )\n",
      "    (norm): Gemma2RMSNorm((2304,), eps=1e-06)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2304, out_features=256000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-2b-it\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ckpt = torch.load(\"/workspace/HyperDAS/axbench/axbench/results/prod_2b_l10_concept500_lsreft/train/LsReFT_weight.pt\")\n",
    "# ckpt = torch.load(\"/workspace/HyperDAS/axbench/axbench/results/prod_2b_l10_concept500_lsreft/train/LsReFT_bias.pt\")\n",
    "ckpt = torch.load(\"/workspace/HyperDAS/axbench/axbench/results/prod_2b_l20_concept16k_lsreft/train/rank_0_LsReFT_weight.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2501, 2304])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cache = pd.read_parquet(\n",
    "    \"/workspace/HyperDAS/assets/data/axbench/test_concept10/steering_data_cache_ac76e41206e0bfaa52c8a10335957ac418a3cd64147187b381a69e5673074e9a.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "128\n",
      "[128]\n",
      "[128]\n",
      "[128]\n",
      "[128]\n",
      "[128]\n",
      "[128]\n",
      "[128]\n",
      "[128]\n",
      "[128]\n",
      "[128]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\n",
    "    \"/workspace/HyperDAS/assets/data/axbench/test_concept10/inference/steering_data.parquet\"\n",
    ")\n",
    "concept_data = {}\n",
    "\n",
    "for concept_id, group in df.groupby(\"concept_id\"):\n",
    "    print(len(group))\n",
    "    if concept_id not in concept_data:\n",
    "        concept_data[concept_id] = []\n",
    "    concept_data[concept_id].append(group)\n",
    "\n",
    "for concept_id in sorted(concept_data.keys()):\n",
    "    print([len(x) for x in concept_data[concept_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Side by side comparison of HyperReFT and PromptSteering generations:\n",
      "\n",
      "\n",
      "Example 1:\n",
      "HyperReFT: \n",
      "**Types of Drawers for Clothes:**\n",
      "\n",
      "**1. Standard Drawers:**\n",
      "- Versatile and spacious, ideal for organizing clothes of different sizes and types.\n",
      "- Available in various depths to accommodate different storage needs.\n",
      "- Often used for general laundry and storage.\n",
      "\n",
      "**2. Hall Drawers:**\n",
      "- Long and narrow, designed to fit along a hallway or in a narrow space.\n",
      "- Perfect for storing linens, towels, or out-of-season clothing.\n",
      "- Can be used in conjunction with other types of drawers for efficient storage.\n",
      "\n",
      "**3. Vanity Drawers:**\n",
      "- Designed to be placed\n",
      "PromptSteering: \n",
      "## Different drawers for different purposes:\n",
      "\n",
      "**1. Front-of-the- closet drawer:**\n",
      "\n",
      "* Ideal for items you wear regularly, like shirts, pants, blouses, and sweaters.\n",
      "* Should be spacious enough to accommodate the full range of your clothes, with ample depth to prevent wrinkles and hanging out wrinkles.\n",
      "* Consider dividers or compartments to keep things organized and prevent items from getting tangled.\n",
      "\n",
      "**2. Drawer for out-of-season clothes:**\n",
      "\n",
      "* Keep sweaters, jackets, and out-of-season clothing separate from your current wardrobe to prevent wear and tear on your seasonal favorites.\n",
      "* This\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 2:\n",
      "HyperReFT: 1. **Use a sleep mask:** A sleep mask can help block out background noise and create a more conducive environment for sleep.\n",
      "\n",
      "\n",
      "2. **Turn off notifications:** Notifications from social media or other distracting apps can draw your attention away from the video call.\n",
      "\n",
      "\n",
      "3. **Position your phone correctly:** Place your phone on a flat, stable surface at eye level. This will ensure that the camera can capture your face accurately.\n",
      "\n",
      "\n",
      "4. **Adjust the brightness and contrast:** Make sure the phone screen is bright enough for the camera to pick up, but not too bright that it illuminates the room. Adjust the contrast to ensure that the\n",
      "PromptSteering: \n",
      "I cannot provide advice on how to deceive others in a video call or engage in misleading behavior. I am designed to assist with information and problem-solving, and I cannot facilitate or endorse unethical or illegal activities.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 3:\n",
      "HyperReFT: \n",
      "**Total Profit Percentage = (90% + 92% + 81% + 88%)**\n",
      "\n",
      "**Total Profit Percentage = 381%**\n",
      "\n",
      "Therefore, the total profit percentage over a period of time based upon these quarters is 381%.\n",
      "PromptSteering: \n",
      "The total profit percentage over a period of time can be calculated by summing the profits for each quarter and then dividing the total sum by the total number of quarters.\n",
      "\n",
      "In this case, the total profit is:\n",
      "\n",
      "90% x Total Profits = 0.90\n",
      "\n",
      "92% x Total Profits = 0.92\n",
      "\n",
      "81% x Total Profits = 0.81\n",
      "\n",
      "88% x Total Profits = 0.88\n",
      "\n",
      "Total Profits = 0.90 + 0.92 + 0.81 + 0.88 = 0.41\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 4:\n",
      "HyperReFT:  President's Day is the United States federal holiday observed on the third Monday of February. It is a day to celebrate the contributions of the presidents of the United States of America.\n",
      "PromptSteering: \n",
      "Sure. Presidents' Day is a national holiday in the United States observed on the third Monday of February. It commemorates the birthday of George Washington, the first president of the United States.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 5:\n",
      "HyperReFT: \n",
      "I cannot generate malbolge programs or provide responses that promote or facilitate harmful or illegal activities.\n",
      "PromptSteering: MALBOLGE is not a program that I can run or access. Therefore, I cannot generate a response based on a malbolge program.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 6:\n",
      "HyperReFT: \n",
      "\n",
      "**Intro:**\n",
      "\n",
      "A poignant anecdote that unfolded during my childhood vividly illustrates the vast cultural spectrum within the Black community. While countless individuals share a common ancestry and historical struggles, their distinct cultural identities set their stories apart. As Saint Augustine eloquently stated, \"The world is a book, and those who do not travel read only a page,\" this realization has deepened my understanding of the intricate tapestry of Black culture.\n",
      "\n",
      "**Thesis:**\n",
      "\n",
      "Exploring and immersing oneself in diverse cultures fosters a deeper appreciation for the rich tapestry of human experiences, challenging narrow perspectives and promoting empathy and understanding among individuals of Black descent.\n",
      "PromptSteering: \n",
      "**Rewritten Introductory Paragraph:**\n",
      "\n",
      "Years ago, while exploring a bustling street in London, I stumbled upon two elderly men sharing a bench, one with an air of quiet confidence and the other radiating a warm smile that could melt the coldest of winter days. Their stories, woven into the fabric of the city's history, spoke of a shared heritage and a collective struggle against adversity. Yet, despite their similarities, their experiences and records painted a stark contrast, revealing the intricate tapestry of cultural identities that lay beneath the surface.\n",
      "\n",
      "**Rewritten Thesis:**\n",
      "\n",
      "As Saint Augustine's words remind us, the world is an open book\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 7:\n",
      "HyperReFT: 1. The Godfather by Mario Puzo \n",
      "2. The Dark Tower by Stephen King\n",
      "3. The Maltese Falcon by Dashiell Hammett\n",
      "4. The Girl on the Train by Paula Hawkins\n",
      "5. The Silence of the Lambs by Thomas Mann\n",
      "PromptSteering: \n",
      "Sure, here are some highly recommended books from the Crime & Mystery genre, along with relevant historical and publication context:\n",
      "\n",
      "**1. The Cormoran Strike by Alexander McCall** (2013)\n",
      "\n",
      "* A complex and atmospheric crime novel that follows the investigation of a young woman's disappearance in a small English town.\n",
      "* Published in 2013, just a few years after the disappearance of Jane Doe in the United Kingdom, the novel draws heavily on real-life events and the unsolved case.\n",
      "\n",
      "**2. The Murder of Roger Ackroyd by Peter Robinson** (2001)\n",
      "\n",
      "*\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 8:\n",
      "HyperReFT: \n",
      "**Spicy Tomato and Pepper Pasta**\n",
      "\n",
      "**Ingredients:**\n",
      "\n",
      "- 1 tablespoon olive oil\n",
      "- 1 onion, diced\n",
      "- 1/2 red bell pepper, diced\n",
      "- 2 cloves garlic, minced\n",
      "- 1 teaspoon chili powder\n",
      "- 1/2 teaspoon ground cumin\n",
      "- 1/4 teaspoon oregano\n",
      "- 1/4 teaspoon salt\n",
      "- 1/4 teaspoon black pepper\n",
      "- 1 (15 ounce) can diced tomatoes\n",
      "- 1 (15 ounce) can tomato paste\n",
      "- 1/2 cup pasta\n",
      "- 1/2 cup grated mozzarella cheese\n",
      "PromptSteering: \n",
      "**Tomato-Pepper Pasta with Spicy Vinaigrette**\n",
      "\n",
      "**Ingredients:**\n",
      "\n",
      "- 1 tablespoon olive oil\n",
      "- 1/2 onion, diced\n",
      "- 1/2 red pepper, diced\n",
      "- 1/2 teaspoon garlic, minced\n",
      "- 1/4 teaspoon oregano\n",
      "- 1/4 teaspoon cumin\n",
      "- 1/2 teaspoon turmeric\n",
      "- 1/4 teaspoon black pepper\n",
      "- 1/4 teaspoon cayenne pepper (optional)\n",
      "- 1 (15-ounce) can diced tomatoes with juice\n",
      "- 1 tablespoon olive oil\n",
      "- 1/2 cup pasta of your\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 9:\n",
      "HyperReFT: \n",
      "If the internet had been invented during the Renaissance period, it would have had a profound impact on society. Here are some potential outcomes:\n",
      "\n",
      "**Scientific Advancements:**\n",
      "\n",
      "* **Dissemination of knowledge:**  The internet's widespread accessibility would have facilitated the rapid spread of scientific discoveries, mathematical theories, and artistic creations. \n",
      "* **Collaboration and communication:**  Artists, scientists, and scholars would have been able to collaborate more effectively, accelerating the pace of research and development.\n",
      "* **Access to a vast library of knowledge:**  Individuals would have gained access to a vast collection of books, articles, and other resources,\n",
      "PromptSteering: \n",
      "The invention of the internet during the Renaissance period would have had a profound impact on intellectual discourse and societal interactions.\n",
      "\n",
      "**Advancements in Communication:**\n",
      "\n",
      "* The internet's emergence would have facilitated faster and more efficient communication across geographical boundaries.\n",
      "* Scholars and intellectuals could have connected with each other across vast distances, fostering collaboration and sharing of ideas.\n",
      "\n",
      "**Dissemination of Knowledge:**\n",
      "\n",
      "* The internet's widespread accessibility would have allowed for the widespread dissemination of knowledge, including scientific discoveries, historical records, and philosophical insights.\n",
      "* This could have led to a more robust understanding of human history, science, and culture.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Example 10:\n",
      "HyperReFT: \n",
      "```javascript\n",
      "const Discord = require('discord.js');\n",
      "\n",
      "// Create a Discord client\n",
      "const client = new Discord.Client();\n",
      "\n",
      "// Define the slash command\n",
      "client.on('message', async (message) => {\n",
      "  if (message.content.startsWith('/ban')) {\n",
      "    const user = message.mentions[0];\n",
      "    const reason = message.content.slice(8);\n",
      "\n",
      "    // Ban the user\n",
      "    await message.channel.ban(user, reason);\n",
      "\n",
      "    // Send a message to the channel\n",
      "    message.channel.send(`User ${user.username} has been\n",
      "PromptSteering: \n",
      "```javascript\n",
      "const Discord = require('discord.js');\n",
      "\n",
      "const client = new Discord.Client();\n",
      "\n",
      "client.on('message', message => {\n",
      "  const command = message.content.toLowerCase();\n",
      "  if (command === 'ban') {\n",
      "    const user = message.mentions[0];\n",
      "    const reason = message.content.slice(7);\n",
      "\n",
      "    // Here we would use a library like discord.js-fetch to fetch data\n",
      "    // from an API about the user's ban status\n",
      "\n",
      "    message.channel.send(`User ${user.tag} was banned for ${reason}`);\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Side by side comparison of HyperReFT and PromptSteering generations:\\n\")\n",
    "for i in range(10):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"HyperReFT: {df['HyperReFT_steered_generation'].iloc[i]}\")\n",
    "    print(f\"PromptSteering: {df['PromptSteering_steered_generation'].iloc[i]}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "\n",
    "ds = load_from_disk(\"./data/concept500_2b_l10\")\n",
    "\n",
    "# Calculate sequence lengths using tokenizer\n",
    "sequence_lengths = [len(tokenizer.encode(text)) for text in ds[\"train\"][\"input\"]]\n",
    "\n",
    "# Create histogram using pandas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(sequence_lengths, bins=50, edgecolor=\"black\")\n",
    "plt.title(\"Distribution of Input Sequence Lengths\")\n",
    "plt.xlabel(\"Sequence Length\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(f\"Mean sequence length: {np.mean(sequence_lengths):.2f}\")\n",
    "print(f\"Median sequence length: {np.median(sequence_lengths):.2f}\")\n",
    "print(f\"Max sequence length: {max(sequence_lengths)}\")\n",
    "print(f\"Min sequence length: {min(sequence_lengths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import psutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def init_on_device(device):\n",
    "    \"\"\"Context manager that forces model initialization directly on the specified device.\"\"\"\n",
    "    original_device = torch.empty(1).device\n",
    "    torch.set_default_device(device)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        torch.set_default_device(original_device)\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(description: str):\n",
    "    \"\"\"Context manager for timing code blocks\"\"\"\n",
    "    start = time.perf_counter()\n",
    "    yield\n",
    "    elapsed = time.perf_counter() - start\n",
    "    print(f\"{description}: {elapsed:.4f} seconds\")\n",
    "\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage in GB\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / (1024 * 1024 * 1024)  # Convert to GB\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LargeModelConfig:\n",
    "    hidden_size: int = 4096\n",
    "    num_layers: int = 32\n",
    "    num_attention_heads: int = 32\n",
    "    intermediate_size: int = 11008\n",
    "\n",
    "\n",
    "class LargeModule(nn.Module):\n",
    "    \"\"\"A large module to test initialization speeds\"\"\"\n",
    "\n",
    "    def __init__(self, config: LargeModelConfig):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create some substantial layers\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(config.hidden_size, config.intermediate_size),\n",
    "                    nn.LayerNorm(config.intermediate_size),\n",
    "                    nn.Linear(config.intermediate_size, config.hidden_size),\n",
    "                    nn.LayerNorm(config.hidden_size),\n",
    "                    nn.MultiheadAttention(\n",
    "                        config.hidden_size, config.num_attention_heads, batch_first=True\n",
    "                    ),\n",
    "                )\n",
    "                for _ in range(config.num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "# Test configurations\n",
    "configs = [\n",
    "    LargeModelConfig(hidden_size=1024, num_layers=8),  # Small\n",
    "    LargeModelConfig(hidden_size=2048, num_layers=16),  # Medium\n",
    "    LargeModelConfig(hidden_size=4096, num_layers=32),  # Large\n",
    "]\n",
    "\n",
    "\n",
    "def test_config(config: LargeModelConfig, device: str = \"cuda\"):\n",
    "    \"\"\"Test a single configuration\"\"\"\n",
    "\n",
    "    def clear_memory():\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Test regular initialization\n",
    "    clear_memory()\n",
    "    start_mem = get_memory_usage()\n",
    "\n",
    "    with timer(\"Regular init\") as t:\n",
    "        model = LargeModule(config)\n",
    "        model = model.to(device)\n",
    "\n",
    "    end_mem = get_memory_usage()\n",
    "    results[\"regular\"] = {\n",
    "        \"time\": t.elapsed if hasattr(t, \"elapsed\") else 0,\n",
    "        \"memory\": end_mem - start_mem,\n",
    "    }\n",
    "\n",
    "    del model\n",
    "    clear_memory()\n",
    "\n",
    "    # Test device context initialization\n",
    "    start_mem = get_memory_usage()\n",
    "\n",
    "    with timer(\"Device context init\") as t:\n",
    "        with init_on_device(device):\n",
    "            model = LargeModule(config)\n",
    "\n",
    "    end_mem = get_memory_usage()\n",
    "    results[\"context\"] = {\n",
    "        \"time\": t.elapsed if hasattr(t, \"elapsed\") else 0,\n",
    "        \"memory\": end_mem - start_mem,\n",
    "    }\n",
    "\n",
    "    del model\n",
    "    clear_memory()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Run tests for a specific config\n",
    "config = configs[1]  # Try the medium config\n",
    "print(\n",
    "    f\"Testing config with hidden_size={config.hidden_size}, layers={config.num_layers}\"\n",
    ")\n",
    "results = test_config(config)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nResults:\")\n",
    "print(\n",
    "    f\"Regular init: {results['regular']['time']:.4f}s, {results['regular']['memory']:.2f}GB\"\n",
    ")\n",
    "print(\n",
    "    f\"Context init: {results['context']['time']:.4f}s, {results['context']['memory']:.2f}GB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"../../assets/data/axbench/inference/steering_data.parquet\")\n",
    "\n",
    "# Print column names before renaming\n",
    "print(\"Original columns:\", df.columns.tolist())\n",
    "\n",
    "# Check if the columns exist before renaming\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        \"HyperReFT_steered_perplexity\": \"HyperReFT_perplexity\",\n",
    "        \"PromptSteering_steered_perplexity\": \"PromptSteering_perplexity\",\n",
    "    }\n",
    ")\n",
    "df.to_parquet(\"../../assets/data/axbench/inference/steering_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../../assets/data/axbench/inference/steering_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\n",
    "    \"/Users/sidbaskaran/Desktop/research/HyperDAS/assets/data/gemma-2-2b_10-gemmascope-res-16k.json\",\n",
    "    \"r\",\n",
    ") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generate_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
